{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics | BAIS:6100\n",
    "# Homework 5. Text Classification and Clustering, Topic Modeling, and Keyword Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 questions, 7 points in total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fill in the Python statements needed to complete all the questions below. \n",
    "- Program everything inside this notebook. \n",
    "- Use only one cell per question. \n",
    "- Each code cell must be run with no errors.\n",
    "- Do not contain any unnecessary code in your answer. (Only the final outcome will be regarded as your answer.)\n",
    "- If the question requests that you store information in a certain variable, use the specific variables name (case sensitive).\n",
    "- All problems must be solved in a programmable way.\n",
    "- When you are done, make sure to save your notebook and then click Restart & Run All before subimission to create a clean version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are going to use a data set from Kaggle.com, which contains 50,000 movie reviews from IMDB and their sentiments. For simplicity, you are going to drop all duplicates and reduce the size of the dataset to 5,000. Run the code cell below to get a dataframe `df`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMDB Dataset of 50K Movie Reviews: https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not make any change to this cell. Just run this cell.\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "\n",
    "df = pd.read_csv(\"classdata/IMDB_Dataset.csv\")\n",
    "df = df.drop_duplicates([\"review\"])\n",
    "df = df.sample(n=5000, replace=False, random_state=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. (0.2 pts) There are two unique values in the `sentiment` column of `df`, which are *positive* and *negative*. Show the count for each value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. (0.4 pts) You are going to develop a binary classification model that is able to classify the sentiment of text as either positive or negative. The words in the `review` column will be used as the features of the model, and the sentiments in the `sentiment` column will be used as the target of the model. Do the following in order:\n",
    "- Initialize a TfidfVectorizer object. Apply TF-IDF and L2 normalization, use the default English stopwords provided by the Scikit-Learn package, and set the maximum document frequency to 0.7. \n",
    "- Fit and transform the `review` column using the vectorizer and save it in `X`. Then, save the `sentiment` column in `y`. \n",
    "- Split `X` and `y` into `X_train`, `X_test`, `y_train`, and `y_test`, such that the test set size is 20% of the entire data set. Set `random_state` to 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. (0.8 pts) In order to develop a classifier using k-NNs, do the following in order:\n",
    "- Using 10-fold cross validation, find the optimal `n_neighbors` parameter value that yields the best performance. Try 1, 2, 3, 4, 5, 6, 7, 8, 9, and 10 as parameter value candidates. \n",
    "- Using the `train_test` function in the code cell below, fit the k-NNs model with the optimal parameter value found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not make any change to this cell. Just run this cell.\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def train_test(X_train, X_test, y_train, y_test, classifier):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    \n",
    "    print(\"Train score: {:.2f}\".format(classifier.score(X_train, y_train)))\n",
    "    print(\"Test score: {:.2f}\\n\".format(classifier.score(X_test, y_test)))\n",
    "    print(\"Classification report:\\n{}\".format(classification_report(y_test, pred, zero_division=0)))\n",
    "    print(confusion_matrix(y_test,pred))\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. (0.4 pts) There are three new texts as below, on which you want to predict the sentiments. Applying the fitted k-NN model to the new texts, save the list of predictions made in the variable `ans4`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not make any change to this cell. Just run this cell.\n",
    "text1 = \"A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"\"has got all the polari\"\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\"\n",
    "text2 = \"This show was an amazing, fresh & innovative idea in the 70's when it first aired. The first 7 or 8 years were brilliant, but things dropped off after that. By 1990, the show was not really funny anymore, and it's continued its decline further to the complete waste of time it is today.<br /><br />It's truly disgraceful how far this show has fallen. The writing is painfully bad, the performances are almost as bad - if not for the mildly entertaining respite of the guest-hosts, this show probably wouldn't still be on the air. I find it so hard to believe that the same creator that hand-selected the original cast also chose the band of hacks that followed. How can one recognize such brilliance and then see fit to replace it with such mediocrity? I felt I must give 2 stars out of respect for the original cast that made this show such a huge success. As it is now, the show is just awful. I can't believe it's still on the air.\"\n",
    "text3 = \"Encouraged by the positive comments about this film on here I was looking forward to watching this film. Bad mistake. I've seen 950+ films and this is truly one of the worst of them - it's awful in almost every way: editing, pacing, storyline, 'acting,' soundtrack (the film's only song - a lame country tune - is played no less than four times). The film looks cheap and nasty and is boring in the extreme. Rarely have I been so happy to see the end credits of a film. <br /><br />The only thing that prevents me giving this a 1-score is Harvey Keitel - while this is far from his best performance he at least seems to be making a bit of an effort. One for Keitel obsessives only.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "ans4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. (0.4 pts) Develop a logistic regression model using the same `X_train`, `X_test`, `y_train`, and `y_test`. Applying the logistic regression model to the same new texts, save the list of predictions in the variable named `ans5`. Note that you do not have to perform cross validation this time, as there are no parameters to optimze. Do not redefine `X_train`, `X_test`, `y_train`, `y_test`, and `X_new`. You just reuse them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "ans5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. (1.4 pts) You are going to find 10 clusters of similar reviews using k-means clustering. Again, the words in the `review` column will be used as the features of the model, so you can continue to use `X`. Do the following in order:\n",
    "- Initialize a KMeans object by setting the number of clusters accordingly and `random_state` to 0. \n",
    "- Fit the model with `X`. This may take several minutes to complete. \n",
    "- Add a new column `cluster` to `df`, such that each review is assigned a cluster number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. (0.2 pts) Show the count for each value in the `cluster` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. (0.2 pts) Get a random sample of ten rows from the largest cluster and save the resulting dataframe in the `ans8` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "ans8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. (1.5 pts) You are going to find 20 topics using LDA topic modeling. Again, the words in the `review` column will be used as the features of the model, so you can continue to use `X`. Do the following in order:\n",
    "- Initialize an LDA object by setting the number of components, or topics, accordingly and `random_state` to 0. \n",
    "- Fit the model with `X`. \n",
    "- Using the `show_topics` function in the code cell below, show all the topics identified, each with its five most contributing words and their scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not make any change to this cell. Just run this cell.\n",
    "def show_topics(model, feature_names, num_top_words):\n",
    "    for topic_idx, topic_scores in enumerate(model.components_):\n",
    "        print(\"*** Topic {}:\".format(topic_idx))\n",
    "        print(\" + \".join([\"{:.2f} * {}\".format(topic_scores[i], feature_names[i]) for i in topic_scores.argsort()[::-1][:num_top_words]]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. (1.5 pts) You are going to plot a keyword network graph. First, you need to add a new column `words` to `df`, such that each value in the new column is a list of tokenized words of the text in the `review` column. Run the code cell below. Then, plot a keyword network graph in a circular layout on the top 20 most common keywords, using the global and local stopwords defined in the code cell below. Adjust the node weights, edge weights, and font size on your own, such that it can help the visualization make more sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not make any change to this cell. Just run this cell.\n",
    "import nltk\n",
    "\n",
    "df[\"words\"] = df.review.apply(lambda x: nltk.word_tokenize(x))\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "global_stopwords = stopwords.words(\"english\")\n",
    "local_stopwords = [c for c in string.punctuation] +\\\n",
    "                  [\"''\", '``', '...', \"'s\", 'also', 'br', 'could', 'even', 'get', 'made', 'make', \n",
    "                   'many', 'much', \"n't\", 'one', 'really', 'would']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that you have completed all the questions, click Kernel > Restart & Run All to creat a clean version of this notebook and check if all cells have run as expected. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
