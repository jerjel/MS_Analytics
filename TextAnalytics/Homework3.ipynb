{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics | BAIS:6100\n",
    "# Homework 3. Basic NLP Techniques & Keyword Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 questions, 7 points in total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fill in the Python statements needed to complete all the questions below. \n",
    "- Program everything inside this notebook. \n",
    "- Use only one cell per question. \n",
    "- Each code cell must be run with no errors.\n",
    "- Do not contain any unnecessary code in your answer. (Only the final outcome will be regarded as your answer.)\n",
    "- If the question requests that you store information in a certain variable, use the specific variables name (case sensitive).\n",
    "- All problems must be solved in a programmable way.\n",
    "- When you are done, make sure to save your notebook and then click Restart & Run All before subimission to create a clean version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Note that you will have to import some modules needed to complete this homework and also reuse some of the user-defined functions you have used at class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. (0.5 pts) Read all the twelve CSV files in the `classdata/tweets` folder, the file names of which start with *tweets_happy_*, and create a dataframe `df` that contains all tweets from each file. Note that you do not have to create random samples from each month. Each tweet text in the data has a hashtag *#happy*. Finally, explicitly convert the types of the two columns `user_name` and `text` of `df` to string in order to ensure that they are strings.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "len(df) == 94704     # Expected output: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. (1 pt) Add new columns `tagged_words`, `subjectivity`, and `user_gender` to `df`. It may take several minutes to run the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "df[[\"text\", \"tagged_words\", \"subjectivity\", \"user_name\", \"user_gender\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. (1 pt) List the top-50 most common words in the `text` column along with their frequencies, considering both the global and local stopwords. You will need to define your own local stopwords that suit the *#happy* corpus. You may treat emojis and URLs as normal words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Make sure NOT to remove important keywords by including them in your local stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. (1 pt) Select from `df` the rows with the subjectivity score larger than or equal to 0.5 and posted by female users. List the top-50 most common words in the the selected text along with their frequencies, reusing the global and local stopwords defined in question 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. (2 pts) Using a regular expression, add a new column `hashtags` to `df`, such that each value in the column contains a list of hashtags in the `text` column value (refer to the in-class example in Module 2). List the top-50 most common <b>hashtags</b> in the `text` column along with their frequencies, considering no stopwords. When counting each hashtag, treat them as lowercase to avoid case variations. For example, the first three tuples in the list look as follows."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "('#happy', 93879),\n",
    "('#taeyeon', 10982),\n",
    "('#life', 9631)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Hint: you will have to modify the body of the `get_counter` function, such that it can iterate over the `hashtags` column, not over the `tagged_words` column.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. (1 pt) Draw a word cloud that visualizes the top-100 most common <b>hashtags</b>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. (0.5 pts) Get the frequency of the hashtag '*#happybirthday*' and save it in the variable `ans7`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "ans7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that you have completed all the questions, click Kernel > Restart & Run All to creat a clean version of this notebook and check if all cells have run as expected. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
