{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics | BAIS:6100\n",
    "# Module 8: Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructor: Kang-Pyo Lee "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset into a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "\n",
    "df = pd.read_csv(\"classdata/emails.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GitHub - randerson112358/Python/Email_Spam_Detection: https://github.com/randerson112358/Python/tree/master/Email_Spam_Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.spam.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.Series.value_counts: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.text.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep=\"first\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.DataFrame.drop_duplicates: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to build a binary <b>classification</b> model that is able to classify an email text as spam or non-spam. \n",
    "- Feature variables: words in the email body texts\n",
    "- Outcome variable  : the spam column (1:spam, 0:non-spam)\n",
    "- Records          : emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"classdata/images/classification.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(use_idf=True, norm=\"l2\", stop_words=\"english\", max_df=0.7)\n",
    "X = vectorizer.fit_transform(df.text)\n",
    "y = df.spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The words in the document-term matrix will be used as features of the model and the spam column as the outcome variable of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5,695 documents and 36,995 words, or features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=\"https://docs.splunk.com/images/thumb/3/3b/TrainTest.png/1100px-TrainTest.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.model_selection.train_test_split: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X_train` and `y_train` will be used in training the model, while `X_test` and `y_test` will be used in testing the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with k-Nearest Neigobors (k-NNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Choose a classficiation algorithm to try"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Initialize a model object with initial parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)     # The number of neighbors to consider, or k, is set to 1. \n",
    "knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.neighbors.KNeighborsClassifier: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Fit the model using the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Check the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_train, y_train), knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, only using the test data, we are going to compare the true outcome values (`y_test`) and the predicted outcome values (`pred`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.metrics.classification_report: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Precision</b> is the fraction of relevant (correct) instances among the retrieved instances, while <b>recall</b> is the fraction of relevant (correct) instances that were retrieved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=\"https://miro.medium.com/max/1872/1*pOtBHai4jFd-ujaNXPilRg.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- True positive: classifying what is true as true (good), e.g., diagnosing a flu patient with flu\n",
    "- False positive: classifying what is false as true (bad), e.g., diagnosing a no flu patient with flu \n",
    "- True negative: classifying what is false as false (good), e.g., diagnosing a no flu patient with no flu\n",
    "- False negative: classifying what is true as false (bad), e.g., diagnosing a flu patient with no flu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>F-measure</b> is the harmonic mean of precison and recall, which is approximately the average of the two when they are close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/dd577aee2dd35c5b0e349327528a5ac606c7bbbf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.metrics.confusion_matrix: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Perform cross validation and choose the best parameters if there are parameters to optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation is used to find a set of parameters that yield the best performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation: evaluating estimator performance: https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "scores_k1 = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "scores_k1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.model_selection.cross_val_score: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that cross validation only deals with the training set. It returns a list of the accuracy scores of the five splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_k1.mean(), scores_k1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "scores_k3 = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "scores_k3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_k3.mean(), scores_k3.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "score_max = 0                      # Score_max is a temoporay variable to store the max score \n",
    "for param in [1, 3, 10, 30]:\n",
    "    model = KNeighborsClassifier(n_neighbors=param)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(\"k = {}: {}\\n{:.3f}, {:.3f}\\n\".format(param, scores, scores.mean(), scores.std()))\n",
    "    \n",
    "    if scores.mean() > score_max:\n",
    "        score_max = scores.mean()\n",
    "        param_best = param         # Param_best is a temoporay variable to store the best parameter \n",
    "        \n",
    "print(\"Highest score : {:.3f} when k = {}\".format(score_max, param_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model turned out to perform best when k = 1, so we choose 1 as k in our final model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Build the final model with the best parameter(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(X_train, X_test, y_train, y_test, classifier):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred = classifier.predict(X_test)\n",
    "    \n",
    "    print(\"Train score: {:.2f}\".format(classifier.score(X_train, y_train)))\n",
    "    print(\"Test score: {:.2f}\\n\".format(classifier.score(X_test, y_test)))\n",
    "    print(\"Classification report:\\n{}\".format(classification_report(y_test, pred, zero_division=0)))\n",
    "    print(confusion_matrix(y_test,pred))\n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"k = {}\".format(param_best))\n",
    "knn = KNeighborsClassifier(n_neighbors=param_best)\n",
    "knn = train_test(X_train, X_test, y_train, y_test, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `knn` is ready to be used for predictions on new unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {}\n",
    "summary[\"k-NNs\"] = round(knn.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `summary` dictionary is used to keep the best performance for each algorithm.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Make predictions on new unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Subject: From Raphael Kamara\\\n",
    "Good day dear,\\\n",
    "Permit me to inform you of my desire of going into business relationship with you. I got your contact from the International web site directory. I prayed over it and selected your name among other names due to what my mind told me to me that you are a reputable and trust worthy person I can expose my ordeal to and do business with. So I must not hesitate to confide in you for this simple and sincere business.\\\n",
    "I am Raphael Kamara and my younger sister Juliet Kamara, the only son and daughter of late Mr and Mrs Vincent Kamara. My father was a very wealthy cocoa merchant in Abidjan, the economic capital of Ivory Coast, before he was poisoned to death by his business associates on one of their outing to discus on a business deal.\\\n",
    "When my mother died on the 6th August 2016, my father took me special because I am the only child and motherless. Before the death of my father on 30th November 2018 in a private hospital here in Abidjan, he secretly called me on his bedside and told me that he has a sum of $7.500.000 (seven million, five hundred thousand US dollars) left in a suspense account in a local Bank here in Abidjan, that he used my name as his only child for the next of kin in deposit of the fund. He explained to me that it was because of this wealth and some huge amount of money his business associates supposed to balance him from the deal they had, that he was poisoned by his business associates, that I should seek for a God fearing foreign partner in a country of my choice where I will transfer this money and use it for investment purpose, (such as real estate management).\\\n",
    "Please, I am honourably seeking your assistance in the following ways.\\\n",
    "1) To receive the money for me in your account by providing a Bank account where this money would be transferred to.\\\n",
    "2) To serve as the guardian of this since I am a boy of 17 years and I do not have business experience.\\\n",
    "3) To help me come over to your country as soon as the money is transferred to your account so that we will continue our education and a new life.\\\n",
    "I am willing to give you 20% of the sum as compensation for effort input after the successful transfer of this fund to your designate account overseas. Anticipating to hear from you quick please. Thanks and God Bless.\\\n",
    "Yours faithfully\\\n",
    "Raphael and Juliet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"Subject: LETTER\\\n",
    "I genuinely ask for your investment idea!!!\\\n",
    "I write to you in regard of a good and profitable proposal i will like us to complete together.\\\n",
    "My name is Mr. Joseph Sawadogo, i work with a reputable Financial Security Firm here in Africa. I have an interesting business proposal i wish to share with you. We will share the fund involve 50% to you while 50% to me after successful transfer of the fund into your account.\\\n",
    "I will give you more details on receiving your response.\\\n",
    "Sincerely Yours,\\\n",
    "Mr. Joseph Sawadogo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"Subject: Watts Group Rentals - Holiday Office Hours\\\n",
    "Good Afternoon!\\\n",
    "Watts Group will be closed tomorrow, Thursday December 24th and Wednesday December 25th for Christmas Eve and Christmas Day. We will re-open on Thursday, December 26th at 8:00AM.\\\n",
    "We wish everyone a safe and happy holiday!\\\n",
    "Watts Group Rentals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text4 = \"Subject: All school PJ day tomorrow!\\\n",
    "Hello,\\\n",
    "Tomorrow will be an all school pajama day at Weber!  Also, tomorrow night there will be Pajama Storytime tomorrow night in the Weber library from 6:30-7:15.  Please feel free to donate any new pajamas (size infant to adult) and any new/gently used books!\\\n",
    "Best\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text5 = \"Hello,\\\n",
    "We just merged all of staff calendars and we cannot give you space Friday, October 18th. That is univ of Iowa homecoming parade and the development office and students are hosting a chili dinner and parade watching. I can offer you Friday the 11th or 25th.\\\n",
    "Sorry for the change!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_texts = [text1, text2, text3, text4, text5]\n",
    "X_new = vectorizer.transform(new_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to transform the new data, as the model was trained on the transformed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two texts are classified as spam, while the rest three as no spam. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Modeling with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.linear_model.LogisticRegression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(lr, X_train, y_train, cv=5)\n",
    "print(\"{}\\n{:.3f}, {:.3f}\".format(scores, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no parameter to optimize using cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = train_test(X_train, X_test, y_train, y_test, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Logistic Regression\"] = round(lr.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.naive_bayes.MultinomialNB: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(mnb, X_train, y_train, cv=5)\n",
    "print(\"{}\\n{:.3f}, {:.3f}\".format(scores, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = train_test(X_train, X_test, y_train, y_test, mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Multinomial Naive Bayes\"] = round(mnb.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No text is classified as spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Linear Support Vector Machines (SVMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC(C=1)\n",
    "svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.svm.LinearSVC: https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = train_test(X_train, X_test, y_train, y_test, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_max = 0\n",
    "for param in [0.01, 0.03, 0.1, 0.3, 1, 3, 10]:\n",
    "    model = LinearSVC(C=param)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(\"C = {}: {}\\n{:.3f}, {:.3f}\\n\".format(param, scores, scores.mean(), scores.std()))\n",
    "    \n",
    "    if scores.mean() > score_max:\n",
    "        score_max = scores.mean()\n",
    "        param_best = param\n",
    "        \n",
    "print(\"Highest score : {:.3f} when C = {}\".format(score_max, param_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"C = {}\".format(param_best))\n",
    "svm = LinearSVC(C=param_best)\n",
    "svm = train_test(X_train, X_test, y_train, y_test, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Linear SVMs\"] = round(svm.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Kernelized Support Vector Machines (KSVMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "ksvm = SVC(C=1, kernel=\"rbf\", gamma=\"scale\")\n",
    "ksvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.svm.SVC: https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksvm = train_test(X_train, X_test, y_train, y_test, ksvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_max = 0\n",
    "for param in [0.01, 0.03, 0.1, 0.3, 1, 3, 10]:\n",
    "    model = SVC(C=param, kernel=\"rbf\", gamma=\"scale\")\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(\"C = {}: {}\\n{:.3f}, {:.3f}\\n\".format(param, scores, scores.mean(), scores.std()))\n",
    "    \n",
    "    if scores.mean() > score_max:\n",
    "        score_max = scores.mean()\n",
    "        param_best = param\n",
    "        \n",
    "print(\"Highest score : {:.3f} when C = {}\".format(score_max, param_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"C = {}\".format(param_best))\n",
    "ksvm = SVC(C=param_best)\n",
    "ksvm = train_test(X_train, X_test, y_train, y_test, ksvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Kernelized SVMs\"] = round(ksvm.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksvm.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, ), activation=\"relu\", random_state=0)\n",
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.neural_network.MLPClassifier: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = train_test(X_train, X_test, y_train, y_test, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It may take a couple of hours to run this cell. \n",
    "\n",
    "score_max = 0\n",
    "for param in [10, 30, 100]:\n",
    "    model = MLPClassifier(hidden_layer_sizes=(param, ), activation=\"relu\", random_state=0)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    print(\"hidden_layer_size = {}: {}\\n{:.3f}, {:.3f}\\n\".format(param, scores, scores.mean(), scores.std()))\n",
    "    \n",
    "    if scores.mean() > score_max:\n",
    "        score_max = scores.mean()\n",
    "        param_best = param\n",
    "        \n",
    "print(\"Highest score : {:.3f} when hidden_layer_sizes = {}\".format(score_max, param_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hidden_layer_size = {}\".format(param_best))\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(param_best, ), random_state=0)\n",
    "mlp = train_test(X_train, X_test, y_train, y_test, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"Neural Networks\"] = round(mlp.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose the algorithm that performs best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the performance is high, we can say:\n",
    "- The features used, in this case the words, were actually good predictors, i.e., did have predictive power.\n",
    "- The quality of the labeled data was very good, i.e., the labels were very accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises - Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing a Multiclass Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"classdata/tweets/tweets_emotions.csv\", sep=\"\\t\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to build a multiclass <b>classification</b> model that is able to classify a tweet text as one of the following six emotion types: happiness, sadness, fear, disgust, surprise, and anger. \n",
    "- Feature variables: words in tweet texts\n",
    "- Outcome variable  : emotion type\n",
    "- Records          : documents (tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Biases in the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the problems in classification is biased training data. In our data, over 80% of the records are labeled with happiness. Therefore, when you train your model with this data, most of your predictions will become happiness. One solution is a biased sampling of data, which intentionally removes the majority class examples. This way, of course, you will lose a substantial portion of the data. \n",
    "\n",
    "In our data, let's aim to reduce the number of happiness, sadness, fear, and disgust records to 1,000 to make the data set much less biased. We will not touch the surprise and anger records, as their numbers are less than 1,000.  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "happiness    51855 --> 1000\n",
    "sadness       6496 --> 1000\n",
    "fear          1653 --> 1000\n",
    "disgust       1227 --> 1000\n",
    "surprise       951 -->  951\n",
    "anger          788 -->  788"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_happy = df[df.emotion == \"happiness\"].sample(n=N, random_state=0)\n",
    "df_happy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sad = df[df.emotion == \"sadness\"].sample(n=N, random_state=0)\n",
    "df_fear = df[df.emotion == \"fear\"].sample(n=N, random_state=0)\n",
    "df_disgust = df[df.emotion == \"disgust\"].sample(n=N, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_others = df[(df.emotion == \"surprise\") | (df.emotion == \"anger\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = pd.concat([df_happy, df_sad, df_fear, df_disgust, df_others], axis=0)\n",
    "df_reduced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.concat: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_reduced.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(use_idf=True, norm=\"l2\", stop_words=\"english\", max_df=0.7)\n",
    "X = vectorizer.fit_transform(df_reduced.text)\n",
    "y = df_reduced.emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(lr, X_train, y_train, cv=5)\n",
    "print(\"{}\\n{:.3f}, {:.3f}\".format(scores, scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr = train_test(X_train, X_test, y_train, y_test, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three things to consider when the performance is low:\n",
    "- The quality of the labeled data is not very good, i.e., the labels are not very accurate. \n",
    "- The number of labeled records is not sufficient.\n",
    "- The features used, in this case the words, do not serve as good predictors, i.e., have no predictive power. You may consider re-selecting the features, but that could not work if none of the features have predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Had so much fun last night, thanks to everyone who came out to Slacker's last night and thank you to all of you who keep supporting me and and this incredible music adventure!\"\n",
    "text2 = \"I just hit someone at work with the “See you next decade” and just like that I’ve reached peak\"\n",
    "text3 = \"Today was the best day in my whole life.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_texts = [text1, text2, text3]\n",
    "X_new = vectorizer.transform(new_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr.predict(X_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
