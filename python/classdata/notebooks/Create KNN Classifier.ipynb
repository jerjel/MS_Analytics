{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create K-Nearest Neighbor Classifier Model\n",
    "References: \n",
    "- Documentation scikit-learn (http://scikit-learn.org/stable/documentation.html)\n",
    "- Introduction to Machine Learning with Python (http://shop.oreilly.com/product/0636920030515.do)\n",
    "\n",
    "Scikit-Learn References:\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data file that I serialized in exploration\n",
    "with open(\"data/weather.pkl\", \"rb\") as frb:\n",
    "    weather = joblib.load(frb)\n",
    "\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data for Modeling\n",
    "\n",
    "- Divide the data into train and test subsets\n",
    "- Encode categorical features for training and testing independently\n",
    "- Scale numeric features for the training and testing subsets independently\n",
    "- Concatenate the transformed discrete with the scaled numeric features in each subset\n",
    "\n",
    "- __We handled the missing values in the Data Cleaning and Exploration__\n",
    "    - Next week, we will look at a better way to handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Names of different columns\n",
    "categorical_cols = [\"WindGustDir\", \"RainToday\", \"Month\"]\n",
    "continuous_cols = [\"Sunshine\", \"Humidity3pm\", \"MaxTemp\"]\n",
    "\n",
    "predictor_cols = categorical_cols + continuous_cols\n",
    "target_col = \"RainTomorrow\"\n",
    "\n",
    "X=weather[predictor_cols]\n",
    "y=weather[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, stratify=y)\n",
    "\n",
    "print(\"Population:\\n\",y.value_counts(normalize=True)*100)\n",
    "print(\"Train:\\n\", y_train.value_counts(normalize=True)*100)\n",
    "print(\"Test:\\n\", y_test.value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False, dtype=np.int32, handle_unknown='ignore')\n",
    "encoder.fit(X_train[categorical_cols])\n",
    "\n",
    "scaler = MinMaxScaler().fit(X_train[continuous_cols])\n",
    "\n",
    "# create numeric indicator features for the discrete features to be used in modeling\n",
    "Xtn_discrete = pd.DataFrame(encoder.transform(X_train[categorical_cols]), columns=list(encoder.get_feature_names(input_features=categorical_cols)))\n",
    "\n",
    "# scale the continuous features since I'm using a distance-based algorithm\n",
    "Xtn_continuous = pd.DataFrame(scaler.transform(X_train[continuous_cols]), columns=list(X_train[continuous_cols].columns))\n",
    " \n",
    "#concatenate the continuous and discrete features into one dataframe\n",
    "X_train = pd.concat([Xtn_continuous, Xtn_discrete], axis = 1)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create numeric indicator features for the discrete features to be used in modeling\n",
    "Xt_discrete = pd.DataFrame(encoder.transform(X_test[categorical_cols]), columns=list(encoder.get_feature_names(input_features=categorical_cols)))\n",
    "Xt_continuous = pd.DataFrame(scaler.transform(X_test[continuous_cols]), columns=list(X_test[continuous_cols].columns))\n",
    "\n",
    "#concatenate the continuous and discrete features into one dataframe\n",
    "X_test = pd.concat([Xt_continuous, Xt_discrete], axis = 1)\n",
    "\n",
    "X_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and Fit a KNN Classifier\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "Distance metrics\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html#sklearn.neighbors.DistanceMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's get a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model.predict(X_test.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model.predict_proba(X_test.head(1))#[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix & Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
    "\n",
    "print(y_test.value_counts())\n",
    "\n",
    "# Make predictions against the test set\n",
    "pred = knn_model.predict(X_test)\n",
    "\n",
    "# Show the confusion matrix\n",
    "''' confusion matrix returned with Predicted as the Columns and Actual as the Rows\n",
    "         PN  PP\n",
    "     AN [tn  fp] \n",
    "     AP [fn  tp]\n",
    "'''\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, pred))\n",
    "tn,fp,fn,tp=confusion_matrix(y_test, pred).ravel()\n",
    "print('tn: ',tn)\n",
    "print('fp: ',fp)\n",
    "print('fn: ',fn)\n",
    "print('tp: ',tp)\n",
    "\n",
    "# Find the accuracy scores of the predictions against the true classes\n",
    "print(\"accuracy: %0.3f\" % accuracy_score(y_test, pred))\n",
    "print(\"recall: %0.3f\" % recall_score(y_test, pred, pos_label='Yes'))\n",
    "print(\"precision: %0.3f\" % precision_score(y_test, pred, pos_label='Yes'))\n",
    "print(\"f-measure: %0.3f\" % f1_score(y_test, pred, pos_label='Yes'))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn Plot Confusion Matrix\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "#fig= plt.figure(figsize=(10,10))\n",
    "\n",
    "negative_label='No Rain'\n",
    "positive_label='Rain'\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "                  (\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "    disp = plot_confusion_matrix(knn_model, X_test, y_test,\n",
    "                                 display_labels=[negative_label,positive_label],\n",
    "                                 cmap=plt.cm.Blues,\n",
    "                                 normalize=normalize)\n",
    "    disp.ax_.set_title(title)\n",
    "    disp.ax_.set_xlabel('Predicted')\n",
    "    disp.ax_.set_ylabel('Actual')\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "weather = pd.read_csv('data/weather.csv', parse_dates=['Date'])\n",
    "weather['Month'] = pd.Categorical(weather.Date.dt.month)\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Names of different columns\n",
    "categorical_cols = [\"WindGustDir\", \"RainToday\", \"Month\"]\n",
    "continuous_cols = [\"Sunshine\", \"Humidity3pm\", \"MaxTemp\"]\n",
    "\n",
    "predictor_cols = categorical_cols + continuous_cols\n",
    "target_col = \"RainTomorrow\"\n",
    "\n",
    "X=weather[predictor_cols]\n",
    "y=weather[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, stratify=y)\n",
    "\n",
    "print(\"Population:\\n\",y.value_counts(normalize=True)*100)\n",
    "print(\"Train:\\n\", y_train.value_counts(normalize=True)*100)\n",
    "print(\"Test:\\n\", y_test.value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "num_transformer = Pipeline(steps=[('impute', SimpleImputer(strategy='mean'))\n",
    "                                 ,('scale', MinMaxScaler())])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[('impute',SimpleImputer(strategy='most_frequent'))\n",
    "                                 ,('enc', OneHotEncoder(sparse = False, drop='first', handle_unknown='error'\n",
    "                                                        ,dtype=np.int32))])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', num_transformer, continuous_cols),\n",
    "                                               ('cat', cat_transformer, categorical_cols)]\n",
    "                                 ,remainder='passthrough')\n",
    "\n",
    "pipe_knn = Pipeline(steps=[('preprocess', preprocessor)\n",
    "                            ,('knn', KNeighborsClassifier(n_neighbors=3, metric='euclidean'))])\n",
    "\n",
    "pipe_knn.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = pipe_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's get a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model.predict(X_test.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model.predict_proba(X_test.head(1))#[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix & Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
    "\n",
    "print(y_test.value_counts())\n",
    "\n",
    "# Make predictions against the test set\n",
    "pred = knn_model.predict(X_test)\n",
    "\n",
    "# Show the confusion matrix\n",
    "''' confusion matrix returned with Predicted as the Columns and Actual as the Rows\n",
    "         PN  PP\n",
    "     AN [tn  fp] \n",
    "     AP [fn  tp]\n",
    "'''\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, pred))\n",
    "tn,fp,fn,tp=confusion_matrix(y_test, pred).ravel()\n",
    "print('tn: ',tn)\n",
    "print('fp: ',fp)\n",
    "print('fn: ',fn)\n",
    "print('tp: ',tp)\n",
    "\n",
    "# Find the accuracy scores of the predictions against the true classes\n",
    "print(\"accuracy: %0.3f\" % accuracy_score(y_test, pred))\n",
    "print(\"recall: %0.3f\" % recall_score(y_test, pred, pos_label='Yes'))\n",
    "print(\"precision: %0.3f\" % precision_score(y_test, pred, pos_label='Yes'))\n",
    "print(\"f-measure: %0.3f\" % f1_score(y_test, pred, pos_label='Yes'))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/knn_model.pkl\", \"wb\") as fwb:\n",
    "    joblib.dump(knn_model, fwb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
