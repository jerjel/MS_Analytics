{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Programming in Python | BAIS:6040\n",
    "# Advanced Data Analytics: Machine Learning with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructor: Jeff Hendricks \n",
    "\n",
    "Topics to be covered:\n",
    "- Supervised learning - classification and regression (+ exercises)\n",
    "- Unsupervised learning - clustering (+ exercises)\n",
    "\n",
    "References: \n",
    "- Documentation scikit-learn (http://scikit-learn.org/stable/documentation.html)\n",
    "- Introduction to Machine Learning with Python (http://shop.oreilly.com/product/0636920030515.do)\n",
    "- Python Data Science Handbook by Jake VanderPlas (http://shop.oreilly.com/product/0636920034919.do)\n",
    "- Python for Data Analysis by Wes McKinney (https://www.oreilly.com/library/view/python-for-data/9781491957653/)\n",
    "- Confusion Matrix by Geeks for Geeks (https://www.geeksforgeeks.org/confusion-matrix-machine-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                       # dataframes\n",
    "from seaborn import load_dataset                          # Titanic dataset\n",
    "from sklearn.cluster import KMeans                        # k-means clustering \n",
    "from sklearn.model_selection import train_test_split      # train/test data\n",
    "from sklearn.neighbors import KNeighborsClassifier        # k-NN classification \n",
    "from sklearn.linear_model import LogisticRegression       # logistic regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset into a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"titanic\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Data Dictionary (Variable, Definition, Key)\n",
    "survived     Survival           0 = No, 1 = Yes \n",
    "pclass       Ticket class       1 = 1st, 2 = 2nd, 3 = 3rd \n",
    "sex          Sex \n",
    "age          Age in years \n",
    "sibsp        # of siblings / spouses aboard the Titanic \n",
    "parch        # of parents / children aboard the Titanic \n",
    "fare         Passenger fare \n",
    "embarked     Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Out Unnecessary Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"survived\", \"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"embarked\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Categorical Columns into Numeric Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As most machine learning libraries will only accept numbers as input, every categorical column in a dataset must be replaced with a numerical column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sex = pd.Categorical(df.sex)   # Step 1: declare the column is categorical "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.Categorical: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Categorical.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sex = df.sex.cat.codes         # Step 2: convert each category to its corresponding code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.Series.cat.codes: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.cat.codes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sex.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non-binary Codes - What's the issue?\n",
    "\n",
    "Category Codes imply an ordering and the learning algorithm might overfit or imply a spurious relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.embarked = pd.Categorical(df.embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.embarked = df.embarked.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.embarked.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try a different approach\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"titanic\")\n",
    "df = df[[\"survived\", \"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"embarked\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2=pd.get_dummies(df.embarked, prefix_sep = \"::\", drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.drop('embarked',axis=1), pd.get_dummies(df.embarked, prefix_sep = \"::\", drop_first = False)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCategoricalDummies(df, categoricalList):\n",
    "    return pd.get_dummies(df[categoricalList], prefix_sep = \"::\", drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"titanic\")\n",
    "df = df[[\"survived\", \"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"embarked\"]]\n",
    "\n",
    "categoricalList = ['embarked','sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df.drop(categoricalList,axis=1), createCategoricalDummies(df,categoricalList)], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with categorical variables, most machine learning libraries will not accept null values as input. Every null value in a dataset must be removed or replaced with a numerical value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna()        # Drop all rows with any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's aim to build a classification model using the Titanic dataset that is able to predict whether an imaginery passenger who has a certain class, sex, age, company, fare, and embark location would have survived the accident or not. This is a binary classification problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, suppose there was a man of age 25 who purchased a third class ticket at £7 and was on board by himself, would he probably have died or survived?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df.columns)\n",
    "features.remove('survived')\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"survived\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the goal description above, we predict <i>survived</i> using <i>pclass</i>, <i>sex</i>, <i>age</i>, <i>sibsp</i>, <i>parch</i>, and <i>fare</i>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For supervised learning tasks, you need a feature dataset <i>X</i> and a target dataset <i>y</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.model_selection.train_test_split: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to randomly split the feature and target datasets <i>X</i> and <i>y</i> into two training datasets <i>X_train</i> and <i>y_train</i> and two test datasets <i>X_text</i> and <i>y_test</i>. The parameter `test_size` set to 0.25 means splitting the data into 25% of test data and 75% of training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with k-Nearest Neighbors (k-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)     # Build a new k-NN classification model with k set to 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.neighbors.KNeighborsClassifier(`n_neighbors`=5, `weights`=’uniform’, `algorithm`=’auto’, `leaf_size`=30, `p`=2, `metric`=’minkowski’, `metric_params`=None, `n_jobs`=None, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.neighbors.KNeighborsClassifier: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)                     # Fit the model using the two training datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_train, y_train)                   # Get the training score of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_test, y_test)                     # Get the test score of the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Explained\n",
    "\n",
    "- True Positive (TP) : Observation is positive, and is predicted to be positive.\n",
    "- False Negative (FN) : Observation is positive, but is predicted negative.\n",
    "- True Negative (TN) : Observation is negative, and is predicted to be negative.\n",
    "- False Positive (FP) : Observation is negative, but is predicted positive.\n",
    "\n",
    "#### Classification Rate or Accuracy is given by the relation:\n",
    "- (TP + TN) / (TP + TN + FN + FP) \n",
    "\n",
    "#### Recall\n",
    "- Recall can be defined as the ratio of the total number of correctly classified positive examples divided by the total number of positive examples. \n",
    "- High Recall indicates the class is correctly recognized (small number of FN).\n",
    "- Recall is given by the relation: TP / (TP + FN)\n",
    "\n",
    "#### Precision\n",
    "- For precision we divide the total number of correctly classified positive examples by the total number of predicted positive examples. \n",
    "- High Precision indicates an example labeled as positive is indeed positive (small number of FP).\n",
    "- Precision is given by the relation: TP / (TP + FP)\n",
    "\n",
    "High recall, low precision: Most of the positive examples are correctly recognized (low FN) but there are a lot of false positives.\n",
    "\n",
    "Low recall, high precision: Miss a lot of positive examples (high FN) but those we predict as positive are indeed positive (low FP)\n",
    "\n",
    "#### F-measure\n",
    "- F-measure which uses Harmonic Mean in place of Arithmetic Mean as it punishes the extreme values more.\n",
    "- The F-Measure will always be nearer to the smaller value of Precision or Recall.\n",
    "- F-Measure : (2 * Recall * Precision) / (Recall + Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url=\"https://media.geeksforgeeks.org/wp-content/uploads/Confusion_Matrix1_1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, fbeta_score, classification_report\n",
    "\n",
    "# Make predictions against the test set\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "# Show the confusion matrix\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, pred))\n",
    "\n",
    "# Find the accuracy scores of the predictions against the true classes\n",
    "print(\"accuracy: %0.3f\" % accuracy_score(y_test, pred))\n",
    "print(\"recall: %0.3f\" % recall_score(y_test, pred))\n",
    "print(\"precision: %0.3f\" % precision_score(y_test, pred))\n",
    "print(\"f-measure: %0.3f\" % fbeta_score(y_test, pred, beta=1))\n",
    "print(classification_report(y_test,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person1 = {\"pclass\": 3, \n",
    "           \"age\": 25,\n",
    "           \"sibsp\": 0,\n",
    "           \"parch\": 0,\n",
    "           \"fare\": 7,\n",
    "           \"embarked::Q\":0,\n",
    "           \"embarked::S\":0,\n",
    "           \"sex::male\":1}\n",
    "\n",
    "person2 = {\"pclass\": 1,\n",
    "           \"age\": 8,\n",
    "           \"sibsp\": 1,\n",
    "           \"parch\": 2,\n",
    "           \"fare\": 40,\n",
    "           \"embarked::Q\":1,\n",
    "           \"embarked::S\":0,\n",
    "           \"sex::male\":0}\n",
    "\n",
    "person3 = {\"pclass\": 2,\n",
    "           \"age\": 20,\n",
    "           \"sibsp\": 0,\n",
    "           \"parch\": 0,\n",
    "           \"fare\": 15,\n",
    "           \"embarked::Q\":0,\n",
    "           \"embarked::S\":1,\n",
    "           \"sex::male\":0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose there were three imaginary passengers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = []                                    # X_new contains new data items \n",
    "for person in [person1, person2, person3]:\n",
    "    new_person = [person[\"pclass\"], person[\"age\"], person[\"sibsp\"], person[\"parch\"]\n",
    "                  ,person[\"fare\"], person[\"embarked::Q\"], person[\"embarked::S\"], person[\"sex::male\"]]\n",
    "    X_new.append(new_person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "knn.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The columns of the dataframe sent to predict() have to be in the same order as X_train\n",
    "\n",
    "- Notice the different prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new person as a dataframe\n",
    "person1a = {\"pclass\": 3, \n",
    "           \"sibsp\": 0,\n",
    "           \"parch\": 0,\n",
    "           \"fare\": 7,\n",
    "           \"embarked::Q\":0,\n",
    "           \"embarked::S\":0,\n",
    "           \"sex::male\":1,\n",
    "           \"age\": 25}\n",
    "\n",
    "X_new2 = pd.DataFrame(person1a,index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.predict(X_new2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-NN model predicts that the persons 1 and 3 would have died, whereas person 2 would have survived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver=\"liblinear\")   # Build a new logistic regression model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.linear_model.LogisticRegression(`penalty`=’l2’, `dual`=False, `tol`=0.0001, `C`=1.0, `fit_intercept`=True, `intercept_scaling`=1, `class_weight`=None, `random_state`=None, `solver`=’warn’, `max_iter`=100, `multi_class`=’warn’, `verbose`=0, `warm_start`=False, `n_jobs`=None, `l1_ratio`=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.linear_model.LogisticRegression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions against the test set\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "# Show the confusion matrix\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, pred))\n",
    "\n",
    "# Find the accuracy scores of the predictions against the true classes\n",
    "print(\"accuracy: %0.3f\" % accuracy_score(y_test, pred))\n",
    "print(\"recall: %0.3f\" % recall_score(y_test, pred))\n",
    "print(\"precision: %0.3f\" % precision_score(y_test, pred))\n",
    "print(\"f-measure: %0.3f\" % fbeta_score(y_test, pred, beta=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model predicts that the person 3 would have survived, unlike the prediction of the above k-NN model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that different models could make different predictions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherDf = pd.read_csv('data/weather.csv', index_col=0).dropna()        # Drop all rows with any missing values\n",
    "weatherDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['MinTemp','MaxTemp','Sunshine','Humidity3pm']\n",
    "target = 'Rainfall'\n",
    "\n",
    "## set the independent and dependent variables\n",
    "X=weatherDf[features]\n",
    "y=weatherDf[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with Linear Regression\n",
    "\n",
    "sklearn.linear_model.LinearRegssion: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression #linear regression\n",
    "\n",
    "lr=LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## score for linear regression is the R2\n",
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Accuracy Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, r2_score, mean_squared_error\n",
    "\n",
    "print(lr.score(X_test, y_test))\n",
    "\n",
    "preds = lr.predict(X_test)\n",
    "\n",
    "score = explained_variance_score(y_test, preds)\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "rmse = math.sqrt(mean_squared_error(y_test, preds))\n",
    "r2 = r2_score(y_test, preds)\n",
    "    \n",
    "print(\"score = {:.5f} | MAE = {:.3f} | RMSE = {:.3f} | R2 = {:.5f}\"\n",
    "          .format(score, mae, rmse, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.intercept_)\n",
    "print(lr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs1 = {   \"MinTemp\": 6, \n",
    "           \"MaxTemp\": 32,\n",
    "           \"Sunshine\": 5,\n",
    "           \"Humidity3pm\": 30}\n",
    "\n",
    "obs2 = {   \"MinTemp\": 16, \n",
    "           \"MaxTemp\": 42,\n",
    "           \"Sunshine\": 10,\n",
    "           \"Humidity3pm\": 35}\n",
    "\n",
    "obs3 = {   \"MinTemp\": 10, \n",
    "           \"MaxTemp\": 25,\n",
    "           \"Sunshine\": 7,\n",
    "           \"Humidity3pm\": 60}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = []                                    # X_new contains new data items \n",
    "for obs in [obs1, obs2, obs3]:\n",
    "    new_obs = [obs[\"MinTemp\"], obs[\"MaxTemp\"], obs[\"Sunshine\"], obs[\"Humidity3pm\"]]\n",
    "    X_new.append(new_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lr.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Modeling with Ridge\n",
    "\n",
    "Least Squares with l2 Regularization\n",
    "\n",
    "sklearn.linear_model.Ridge: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "rr=Ridge(solver='svd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## score for ridge regression is the R2\n",
    "rr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Other accuracy measures\n",
    "print(rr.score(X_test, y_test))\n",
    "\n",
    "preds = rr.predict(X_test)\n",
    "\n",
    "score = explained_variance_score(y_test, preds)\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "rmse = math.sqrt(mean_squared_error(y_test, preds))\n",
    "r2 = r2_score(y_test, preds)\n",
    "    \n",
    "print(\"score = {:.5f} | MAE = {:.3f} | RMSE = {:.3f} | R2 = {:.5f}\"\n",
    "          .format(score, mae, rmse, r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises for Supervised Learning (8 questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build another classification model for titanic survivors. This time, build a logistic regression model using pclass, age, and fare as the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"titanic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. You need two variables: X as a feature dataset and y as a target dataset. Select the appropriate eatures in <i>df</i> and assign them to a variable called <i>X</i>. Likewise, select the target in <i>df</i> and assign it to a variable called <i>y</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Split <i>X</i> and <i>y</i> into two training datasets <i>X_train</i> and <i>y_train</i> and two test datasets <i>X_text</i> and <i>y_test</i>. Set the `test_size` to 0.25 and `random_state` to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can build a new logistic regression model <i>lgr</i> as follows. The solver is set to <i>liblinear</i>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression(solver=\"liblinear\")   # Build a new logistic regression model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Fit the logistic regression model <i>lgr</i> using the two training datasets <i>X_train</i> and <i>y_train</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Get the training score and test score, confusion matrix, and classification report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's aim to build a <b>regression</b> model using the Major League Baseball dataset that is able to predict the number of homeruns (HRs) a batter would hit in a single season based on some statistics such as number of games (G), number of at bats (AB), runs scored (R), num of hits (H), number of doubles (2B), number of triples (3B), number of stolens bases (SB), and number of base on balls (BB). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb = pd.read_csv(\"MLB_Batting.csv\")\n",
    "dfb18 = dfb[(dfb.yearID == 2018) & ((dfb.lgID == \"NL\") | (dfb.lgID == \"AL\"))]\n",
    "dfb18.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Data Dictionary (Variable, Definition)\n",
    "playerID       Player ID code\n",
    "yearID         Year\n",
    "stint          player's stint (order of appearances within a season)\n",
    "teamID         Team\n",
    "lgID           League\n",
    "G              Games\n",
    "AB             At Bats\n",
    "R              Runs\n",
    "H              Hits\n",
    "2B             Doubles\n",
    "3B             Triples\n",
    "HR             Homeruns\n",
    "RBI            Runs Batted In\n",
    "SB             Stolen Bases\n",
    "CS             Caught Stealing\n",
    "BB             Base on Balls\n",
    "SO             Strikeouts\n",
    "IBB            Intentional walks\n",
    "HBP            Hit by pitch\n",
    "SH             Sacrifice hits\n",
    "SF             Sacrifice flies\n",
    "GIDP           Grounded into double plays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the goal description above, the features to be used include G, AB, R, H, 2B, 3B, SB, and BB, while the target is HR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"G\", \"AB\", \"R\", \"H\", \"2B\", \"3B\", \"SB\", \"BB\"]\n",
    "target = \"HR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. You need two variables: X as a feature dataset and y as a target dataset. Select the features in <i>dfb18</i> and assign it to a variable called <i>X</i>. Likewise, select the target in <i>dfb18</i> and assign it to a variable called <i>y</i>.\n",
    "\n",
    "Split <i>X</i> and <i>y</i> into two training datasets <i>X_train</i> and <i>y_train</i> and two test datasets <i>X_text</i> and <i>y_test</i>. Set the `test_size` to 0.25 and `random_state` to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can build a new least squares linear regression model <i>lr</i> as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression     # linear regression\n",
    "\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Fit the linear regression model <i>lr</i> using the training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Get the training score and test score, MAE, and RMSE, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Suppose there is a new batter who has the following record. How many home runs would the batter hit using your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batter = {\"G\": 130,\n",
    "          \"AB\": 450,\n",
    "          \"R\": 100,\n",
    "          \"H\": 170,\n",
    "          \"2B\": 60,\n",
    "          \"3B\": 10,\n",
    "          \"SB\": 5,\n",
    "          \"BB\": 80}\n",
    "\n",
    "new_batter = [batter[\"G\"], batter[\"AB\"], batter[\"R\"], batter[\"H\"], batter[\"2B\"], batter[\"3B\"], batter[\"SB\"], batter[\"BB\"]]\n",
    "X_new = [new_batter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's aim to build a clustering model that is able to group, or cluster, all passengers on board of the Titanic into several groups, or clusters, of similar ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"titanic\")\n",
    "\n",
    "df = df[[\"survived\", \"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"embarked\"]]\n",
    "\n",
    "categoricalList = ['embarked','sex']\n",
    "\n",
    "df = pd.concat([df.drop(categoricalList,axis=1), createCategoricalDummies(df,categoricalList)], axis = 1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is no <i>y </i> in unsupervised learning. All you need is just an input dataset <i>X</i>. Also, you do not have to split the data into training and test sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with k-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=0)     # Create a new k-means clustering model with k set to 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class sklearn.cluster.KMeans(`n_clusters`=8, `init`=’k-means++’, `n_init`=10, m`ax_iter`=300, `tol`=0.0001, `precompute_distances`=’auto’, `verbose`=0, `random_state`=None, `copy_x`=True, `n_jobs`=None, `algorithm`=’auto’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.cluster.KMeans: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_                          # Store the values of centroids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_                                   # Store the cluster labels of data items "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each data item in <i>X</i> is assigned a cluster label, which is a number between 0 and k-1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"label\"] = kmeans.labels_                    # Add a new column lable with the clustering labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.value_counts()                          # Count the number of values for each label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.label == 2].sample(n=10, replace=False, random_state=0)  # Select a random sample with 10 rows that have the label 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.label == 0].sample(n=10, replace=False, random_state=0)  # Select a random sample with 10 rows that have the label 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"label\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises for Clustering (6 questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same baseball data, let's aim to build a clustering model that is able to group all batters into 5 clusters of similar ones by looking at the same __8 features__ used in the above regression __exercises__ along with the __target__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a copy of <i>dfb18</i> for clustering. Use <i>dfb18c</i> for your clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfb18c = dfb18.copy()\n",
    "dfb18c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. For clustering, all you need is just an input dataset <i>X</i>. Select the 9 features in <i>dfb18c</i> and assign it to <i>X</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Build a new k-means clustering model <i>kmeans</i>. Set `n_clusters` to 5 and `random_state` to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Fit the clustering model <i>kmeans</i> using the input dataset <i>X</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Assign the resulting labels of <i>kmeans</i> to the new column of <i>dfb18c</i> called <i>label</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Check the number of values for each label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Select a random sample of <i>dfb18c</i> with 10 rows that have the lable 2. For random sampling, set `replace` to False and `random_state` to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
