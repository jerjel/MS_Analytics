{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Programming in Python | BAIS:6040\n",
    "# Files and External Data Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructor: Jeff Hendricks \n",
    "\n",
    "Topics to be covered:\n",
    "- Useful OS functionality\n",
    "- Writing and reading a file (+ exercises)\n",
    "- Writing and reading a CSV file using Pandas\n",
    "- Writing and reading a JSON file (+ exercises)\n",
    "- Working with databases\n",
    "\n",
    "References: \n",
    "- Data Wrangling with Python by By Jacqueline Kazil, Katharine Jarmul (http://shop.oreilly.com/product/0636920032861.do)\n",
    "- Pandas official website (http://pandas.pydata.org/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install XlsxWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json                            # handling JSON files\n",
    "import sqlite3 as sq3                  # communicating with SQLite3 database\n",
    "import os                              # using OS-dependent functionality \n",
    "import pandas as pd                    # handling Pandas dataframes\n",
    "from seaborn import load_dataset       # using the Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful OS dependent functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>os</b> module provides a portable way of using operating system dependent functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>os.listdir(path='.')</b> function returns a list containing the names of the entries in the directory given by path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"./\")                        # The path \".\" means the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[item for item in os.listdir(\"./\") if item.endswith(\".ipynb\")]  # a list of ipynb files in the current directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>os.getcwd()</b> function returns a string representing the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>os.path.isfile(path)</b> function returns True if path is an existing regular file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isfile(\"Data_Programming_in_Python_Part5_Files_and_External_Data_sources.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isfile(\"DPP_Module5_Files_and_External_Data.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>os.path.isdir(path)</b> function returns True if path is an existing directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.isdir(\"newdata2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>os.mkdir(path)</b> function creates a directory named `path`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"newdata2\"):         # Check if there is an existing directory named newdata.\n",
    "    os.mkdir(\"newdata2\")                  # Create a new directory named data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing and reading a file, the first thing you need to do is to open a file in the right mode. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The built-in <b>open()</b> function opens the file provided and returns a corresponding file object. If the file cannot be opened, an OSError is raised. The parameter `mode` is an optional string that specifies the mode in which the file is opened. \n",
    "- \"r\": opens a file for reading. (default)\n",
    "- \"w\": opens a file for writing. Creates a new file if it does not exist, or truncates the file if it exists.\n",
    "- \"a\": opens for appending at the end of the file without truncating it. Creates a new file if it does not exist.\n",
    "- \"b\": opens in binary mode.\n",
    "- \"+\": opens a file for updating (reading and writing)\n",
    "\n",
    "open: https://docs.python.org/3/library/functions.html#open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw = open(\"data/output.txt\", mode=\"w\")\n",
    "fw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>write()</b> method writes the contents of string to the file, returning the number of characters written. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw.write(\"Hello, world!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello, world!\\n\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that writing a string to a file using the <b>write</b> method is practically the same as printing a string using the <b>print</b> function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>close()</b> method closes the file and immediately frees up any system resources used by it. If you do not explicitly close a file, Pythonâ€™s garbage collector will eventually destroy the object and close the open file for you, but the file may stay open for a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python Context Manager ('with')\n",
    "\n",
    "It is good practice to use the <b>with</b> keyword when dealing with file objects. The advantage is that the file is properly closed after its block finishes, which means you do not have to explicitly close the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/output.txt\", mode=\"w\") as fw:\n",
    "    fw.write(\"Hello, world!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing a CSV file with a single column, you need to decide the delimiter to specify the boundary between separate rows, e.g., a new line (\"\\n\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/output.csv\", mode=\"w\") as fw:\n",
    "    fw.write(\"num\\n\")                # Use a new line (\\n) between rows.\n",
    "    \n",
    "    for i in range(10):\n",
    "        fw.write(\"{}\\n\".format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing a CSV file with multiple columns, you also need to decide the delimiter to specify the boundary between separate columns, e.g., comma (\",\") or tab (\"\\t\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/output2.csv\", mode=\"w\") as fw:\n",
    "    fw.write(\"num,col1,col2\\n\")       # Use a comma (,) between columns and a new line (\\n) between rows.\n",
    "    \n",
    "    for i in range(10):\n",
    "        fw.write(\"{},{},{}\\n\".format(i, i*10, i*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"titanic\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/my_titanic.csv\", \"w\") as fw:\n",
    "    header = \"index,survived,pclass,fare\\n\"\n",
    "    fw.write(header)\n",
    "    print(header, end=\"\")            # Print the header row just to check the current status.\n",
    "    \n",
    "    for idx, val in df.iterrows():\n",
    "        survived = val.survived\n",
    "        pclass = val.pclass\n",
    "        fare = val.fare\n",
    "        \n",
    "        row = \"{},{},{},{}\\n\".format(idx, survived, pclass, fare)\n",
    "        fw.write(row)\n",
    "        print(row, end=\"\")           # Print each row to check the current status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/output.txt\", mode=\"r\") as fr:\n",
    "    content = fr.read()                    # Read the whole contents in the file.\n",
    "    print(content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/output2.csv\", mode=\"r\") as fr:\n",
    "    for line in fr:                        # Read the file line by line. \n",
    "        print(line, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/output2.csv\", mode=\"r\") as fr:\n",
    "    lines = fr.readlines()                 # Read the whole contents in the file as a list of lines.\n",
    "                                           # Not recommended if the file is too large to be loaded in memory.\n",
    "    for line in lines:\n",
    "        print(line, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/output2.csv\", mode=\"r\") as fr:\n",
    "    lines = fr.readlines()                 # Read the whole content in the file as a list of lines.\n",
    "    \n",
    "    # Decompose the header row into coloumn names\n",
    "    header = lines[0]\n",
    "    header = header.rstrip()               # Remove the trailing new line in the header.\n",
    "    num, col1, col2 = header.split(\",\")\n",
    "    \n",
    "    # Decompose each line into values\n",
    "    for line in lines[1:]:\n",
    "        line = line.rstrip()               # Remove the trailing new line in each line.\n",
    "        num_val, val1, val2 = line.split(\",\")\n",
    "        print(\"{}: {},\\t{}: {},\\t{}: {}\".format(num, num_val, col1, val1, col2, val2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open(\"data/outputtt.csv\", mode=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises for file writing and reading (6 questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Creat a list <i>l</i> of integers from 1 (inclusive) to 100 (inclusive). Write a CSV file named <i>ex_output.csv</i> under the directory <i>data</i>. The file contains only one column name <i>id</i> in the first row and, starting from the second row, each number from <i>l</i> in each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Continue to use the list <i>l</i>. Write another CSV file named <i>ex_output2.csv</i> under the directory <i>data</i>. The file contains three column names <i>id</i>, <i>square</i>, and <i>cube</i> in the first row and, starting from the second row, each number from <i>l</i>, its square, and its cube in each line. The delimiter between columns is a comma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue to use the dataframe <i>df</i> from the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = load_dataset(\"titanic\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Create a CSV file named <i>ex_titanic.csv</i> under the directory <i>data</i>. The file contains three column names <i>sex</i>, <i>pclass</i> and <i>embark_town</i> in the first row and the values from the corresponding columns of <i>df</i> in the following rows. The delimiter between columns is a tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Create a CSV file named <i>ex_titanic2.csv</i> under the directory <i>data</i>. The file contains the same contents as <i>ex_titanic.csv</i>. In addition, it contains another column named <i>num_fam_mems</i>, meaning the number of family members, which is the sum of the column <i>sibsp</i> (siblings and spouses) and the column <i>parch</i> (parents and children). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Read the file <i>ex_titanic2.csv</i> under the directory <i>data</i> and print the first five rows as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Read the file <i>ex_titanic2.csv</i> under the directory <i>data</i> and print the first five rows under the column <i>embark_town</i>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing a CSV file using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to read a CSV file and analyze the contents in a tabular format with rows and columns, it is a good idea to read the file as a Pandas dataframe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.read_csv: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/pie_rates2.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/pie_rates2.csv\", sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://people.sc.fsu.edu/~jburkardt/data/csv/biostats.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"http://go.microsoft.com/fwlink/?LinkID=521962\", sheet_name=\"Sheet1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.read_excel: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/my_data.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.DataFrame.to_csv: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"data/my_data.xls\", sheet_name=\"Sheet1\", index=False, engine='xlsxwriter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas.DataFrame.to_excel: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BREAK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing and reading a JSON file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON, which stands for JavaScript Object Notation, is one of the most commonly used formats for data transfer. It is preferred, because it is clean, easy to read, and easy to parse. Many websites provide JSON-enabled APIs, or Application Programming Interfaces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {\"IL\": \"Illinois\", \"WI\": \"Wisconsin\", \"IA\": \"Iowa\", \"NE\": \"Nebraska\", \"MN\": \"Minnesota\"}\n",
    "states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>json.dump(obj, fp, ...)</b> function serializes `obj` as a JSON formatted stream to `fp`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/my_states.json\", \"w\") as fw:\n",
    "    json.dump(states, fw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>json.load(fp, ...)</b> deserializes `fp` to a Python object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/my_states.json\", \"r\") as fr:\n",
    "    states_new = json.load(fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you open the JSON file and see the contents, you will see that each data record looks a lot like a Python dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = {'created_at': 'Sun Jun 23 09:27:06 +0000 2019',\n",
    " 'id': 1142725758621818880,\n",
    " 'id_str': '1142725758621818880',\n",
    " 'text': 'Two stunning mental health facts have now been ranked true...I think no one believed them because theyâ€™re so startlâ€¦ https://t.co/Gp5n31SYm1',\n",
    " 'truncated': True,\n",
    " 'entities': {'hashtags': [],\n",
    "  'symbols': [],\n",
    "  'user_mentions': [],\n",
    "  'urls': [{'url': 'https://t.co/Gp5n31SYm1',\n",
    "    'expanded_url': 'https://twitter.com/i/web/status/1142725758621818880',\n",
    "    'display_url': 'twitter.com/i/web/status/1â€¦',\n",
    "    'indices': [117, 140]}]},\n",
    " 'metadata': {'result_type': 'popular', 'iso_language_code': 'en'},\n",
    " 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
    " 'in_reply_to_status_id': None,\n",
    " 'in_reply_to_status_id_str': None,\n",
    " 'in_reply_to_user_id': None,\n",
    " 'in_reply_to_user_id_str': None,\n",
    " 'in_reply_to_screen_name': None,\n",
    " 'user': {'id': 33537967,\n",
    "  'id_str': '33537967',\n",
    "  'name': 'Amy Klobuchar',\n",
    "  'screen_name': 'amyklobuchar',\n",
    "  'location': '',\n",
    "  'description': 'U.S. Senator from Minnesota and candidate for President. Text AMY to 91990 to join our homegrown campaign.',\n",
    "  'url': 'http://t.co/mGGFBfggto',\n",
    "  'entities': {'url': {'urls': [{'url': 'http://t.co/mGGFBfggto',\n",
    "      'expanded_url': 'http://www.amyklobuchar.com',\n",
    "      'display_url': 'amyklobuchar.com',\n",
    "      'indices': [0, 22]}]},\n",
    "   'description': {'urls': []}},\n",
    "  'protected': False,\n",
    "  'followers_count': 705873,\n",
    "  'friends_count': 140906,\n",
    "  'listed_count': 5754,\n",
    "  'created_at': 'Mon Apr 20 14:59:36 +0000 2009',\n",
    "  'favourites_count': 30,\n",
    "  'utc_offset': None,\n",
    "  'time_zone': None,\n",
    "  'geo_enabled': False,\n",
    "  'verified': True,\n",
    "  'statuses_count': 9153,\n",
    "  'lang': 'en',\n",
    "  'contributors_enabled': False,\n",
    "  'is_translator': False,\n",
    "  'is_translation_enabled': False,\n",
    "  'profile_background_color': '026113',\n",
    "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
    "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
    "  'profile_background_tile': False,\n",
    "  'profile_image_url': 'http://pbs.twimg.com/profile_images/1059812997982511105/lgFAlE5t_normal.jpg',\n",
    "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1059812997982511105/lgFAlE5t_normal.jpg',\n",
    "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/33537967/1549830865',\n",
    "  'profile_link_color': '026113',\n",
    "  'profile_sidebar_border_color': 'F6D73F',\n",
    "  'profile_sidebar_fill_color': '89BCEE',\n",
    "  'profile_text_color': '3D3C3D',\n",
    "  'profile_use_background_image': True,\n",
    "  'has_extended_profile': False,\n",
    "  'default_profile': False,\n",
    "  'default_profile_image': False,\n",
    "  'following': False,\n",
    "  'follow_request_sent': False,\n",
    "  'notifications': False,\n",
    "  'translator_type': 'regular'},\n",
    " 'geo': None,\n",
    " 'coordinates': None,\n",
    " 'place': None,\n",
    " 'contributors': None,\n",
    " 'is_quote_status': True,\n",
    " 'quoted_status_id': 1142581281408114689,\n",
    " 'quoted_status_id_str': '1142581281408114689',\n",
    " 'quoted_status': {'created_at': 'Sat Jun 22 23:53:00 +0000 2019',\n",
    "  'id': 1142581281408114689,\n",
    "  'id_str': '1142581281408114689',\n",
    "  'text': 'Minnesota Senator and #2020election Democratic candidate @amyklobuchar claims U.S. suicides have risen by 30% in paâ€¦ https://t.co/dDcFG8epEe',\n",
    "  'truncated': True,\n",
    "  'entities': {'hashtags': [{'text': '2020election', 'indices': [22, 35]}],\n",
    "   'symbols': [],\n",
    "   'user_mentions': [{'screen_name': 'amyklobuchar',\n",
    "     'name': 'Amy Klobuchar',\n",
    "     'id': 33537967,\n",
    "     'id_str': '33537967',\n",
    "     'indices': [57, 70]}],\n",
    "   'urls': [{'url': 'https://t.co/dDcFG8epEe',\n",
    "     'expanded_url': 'https://twitter.com/i/web/status/1142581281408114689',\n",
    "     'display_url': 'twitter.com/i/web/status/1â€¦',\n",
    "     'indices': [117, 140]}]},\n",
    "  'metadata': {'result_type': 'popular', 'iso_language_code': 'en'},\n",
    "  'source': '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>',\n",
    "  'in_reply_to_status_id': None,\n",
    "  'in_reply_to_status_id_str': None,\n",
    "  'in_reply_to_user_id': None,\n",
    "  'in_reply_to_user_id_str': None,\n",
    "  'in_reply_to_screen_name': None,\n",
    "  'user': {'id': 8953122,\n",
    "   'id_str': '8953122',\n",
    "   'name': 'PolitiFact',\n",
    "   'screen_name': 'PolitiFact',\n",
    "   'location': 'Washington, DC',\n",
    "   'description': 'Home of the Truth-O-Meter and independent fact-checking. Part of @Poynter. Sign up for our daily email https://t.co/bfN0WPdGhm.',\n",
    "   'url': 'https://t.co/DPzWZ42N71',\n",
    "   'entities': {'url': {'urls': [{'url': 'https://t.co/DPzWZ42N71',\n",
    "       'expanded_url': 'http://membership.politifact.com',\n",
    "       'display_url': 'membership.politifact.com',\n",
    "       'indices': [0, 23]}]},\n",
    "    'description': {'urls': [{'url': 'https://t.co/bfN0WPdGhm',\n",
    "       'expanded_url': 'http://bit.ly/PolitiFactEmail',\n",
    "       'display_url': 'bit.ly/PolitiFactEmail',\n",
    "       'indices': [103, 126]}]}},\n",
    "   'protected': False,\n",
    "   'followers_count': 635750,\n",
    "   'friends_count': 8147,\n",
    "   'listed_count': 10993,\n",
    "   'created_at': 'Tue Sep 18 15:08:32 +0000 2007',\n",
    "   'favourites_count': 2435,\n",
    "   'utc_offset': None,\n",
    "   'time_zone': None,\n",
    "   'geo_enabled': True,\n",
    "   'verified': True,\n",
    "   'statuses_count': 40621,\n",
    "   'lang': 'en',\n",
    "   'contributors_enabled': False,\n",
    "   'is_translator': False,\n",
    "   'is_translation_enabled': False,\n",
    "   'profile_background_color': 'FFFFFF',\n",
    "   'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
    "   'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
    "   'profile_background_tile': False,\n",
    "   'profile_image_url': 'http://pbs.twimg.com/profile_images/1097902211185692672/RGGYVdxt_normal.png',\n",
    "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1097902211185692672/RGGYVdxt_normal.png',\n",
    "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/8953122/1550238073',\n",
    "   'profile_link_color': '003291',\n",
    "   'profile_sidebar_border_color': '000000',\n",
    "   'profile_sidebar_fill_color': 'DDEEF6',\n",
    "   'profile_text_color': '333333',\n",
    "   'profile_use_background_image': True,\n",
    "   'has_extended_profile': False,\n",
    "   'default_profile': False,\n",
    "   'default_profile_image': False,\n",
    "   'following': False,\n",
    "   'follow_request_sent': False,\n",
    "   'notifications': False,\n",
    "   'translator_type': 'none'},\n",
    "  'geo': None,\n",
    "  'coordinates': None,\n",
    "  'place': None,\n",
    "  'contributors': None,\n",
    "  'is_quote_status': False,\n",
    "  'retweet_count': 19,\n",
    "  'favorite_count': 52,\n",
    "  'favorited': False,\n",
    "  'retweeted': False,\n",
    "  'possibly_sensitive': False,\n",
    "  'lang': 'en'},\n",
    " 'retweet_count': 681,\n",
    " 'favorite_count': 2620,\n",
    " 'favorited': False,\n",
    " 'retweeted': False,\n",
    " 'possibly_sensitive': False,\n",
    " 'lang': 'en'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweet Object: https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status2 = {'created_at': 'Sun Jun 23 13:05:31 +0000 2019',\n",
    " 'id': 1142780726825422848,\n",
    " 'id_str': '1142780726825422848',\n",
    " 'text': 'Joe Sestak, a former congressman from Pennsylvania who lost Senate bids in 2010 and 2016, is now running for presidâ€¦ https://t.co/g6lm9mi0gr',\n",
    " 'truncated': True,\n",
    " 'entities': {'hashtags': [],\n",
    "  'symbols': [],\n",
    "  'user_mentions': [],\n",
    "  'urls': [{'url': 'https://t.co/g6lm9mi0gr',\n",
    "    'expanded_url': 'https://twitter.com/i/web/status/1142780726825422848',\n",
    "    'display_url': 'twitter.com/i/web/status/1â€¦',\n",
    "    'indices': [117, 140]}]},\n",
    " 'metadata': {'result_type': 'popular', 'iso_language_code': 'en'},\n",
    " 'source': '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>',\n",
    " 'in_reply_to_status_id': None,\n",
    " 'in_reply_to_status_id_str': None,\n",
    " 'in_reply_to_user_id': None,\n",
    " 'in_reply_to_user_id_str': None,\n",
    " 'in_reply_to_screen_name': None,\n",
    " 'user': {'id': 13524182,\n",
    "  'id_str': '13524182',\n",
    "  'name': 'Dave Weigel',\n",
    "  'screen_name': 'daveweigel',\n",
    "  'location': 'Washington, D.C.',\n",
    "  'description': 'Covering politics for @washingtonpost. daveweigel@gmail.com, 202-334-7387. @CWAUnion member. Buy my book: https://t.co/qbUTkz3CBR (Avatar by @damnyouregis)',\n",
    "  'url': 'https://t.co/fH66dGGX87',\n",
    "  'entities': {'url': {'urls': [{'url': 'https://t.co/fH66dGGX87',\n",
    "      'expanded_url': 'http://www.daveweigel.com',\n",
    "      'display_url': 'daveweigel.com',\n",
    "      'indices': [0, 23]}]},\n",
    "   'description': {'urls': [{'url': 'https://t.co/qbUTkz3CBR',\n",
    "      'expanded_url': 'http://tinyurl.com/h7wyg2c',\n",
    "      'display_url': 'tinyurl.com/h7wyg2c',\n",
    "      'indices': [106, 129]}]}},\n",
    "  'protected': False,\n",
    "  'followers_count': 468137,\n",
    "  'friends_count': 11200,\n",
    "  'listed_count': 11364,\n",
    "  'created_at': 'Fri Feb 15 17:58:23 +0000 2008',\n",
    "  'favourites_count': 15384,\n",
    "  'utc_offset': None,\n",
    "  'time_zone': None,\n",
    "  'geo_enabled': True,\n",
    "  'verified': True,\n",
    "  'statuses_count': 195624,\n",
    "  'lang': 'en',\n",
    "  'contributors_enabled': False,\n",
    "  'is_translator': False,\n",
    "  'is_translation_enabled': False,\n",
    "  'profile_background_color': '1A1B1F',\n",
    "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme9/bg.gif',\n",
    "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme9/bg.gif',\n",
    "  'profile_background_tile': False,\n",
    "  'profile_image_url': 'http://pbs.twimg.com/profile_images/999649964870451201/-Co_Xkx4_normal.jpg',\n",
    "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/999649964870451201/-Co_Xkx4_normal.jpg',\n",
    "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/13524182/1397875542',\n",
    "  'profile_link_color': '2FC2EF',\n",
    "  'profile_sidebar_border_color': '181A1E',\n",
    "  'profile_sidebar_fill_color': '252429',\n",
    "  'profile_text_color': '666666',\n",
    "  'profile_use_background_image': True,\n",
    "  'has_extended_profile': True,\n",
    "  'default_profile': False,\n",
    "  'default_profile_image': False,\n",
    "  'following': False,\n",
    "  'follow_request_sent': False,\n",
    "  'notifications': False,\n",
    "  'translator_type': 'none'},\n",
    " 'geo': None,\n",
    " 'coordinates': None,\n",
    " 'place': None,\n",
    " 'contributors': None,\n",
    " 'is_quote_status': False,\n",
    " 'retweet_count': 488,\n",
    " 'favorite_count': 1493,\n",
    " 'favorited': False,\n",
    " 'retweeted': False,\n",
    " 'possibly_sensitive': False,\n",
    " 'lang': 'en'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status3 = {'created_at': 'Sat Jun 22 18:07:54 +0000 2019',\n",
    " 'id': 1142494436930260992,\n",
    " 'id_str': '1142494436930260992',\n",
    " 'text': 'Chevron and Exxon are receiving secret waivers intended for small refineries. This administration is putting Iowa fâ€¦ https://t.co/qBcyzZ6IHn',\n",
    " 'truncated': True,\n",
    " 'entities': {'hashtags': [],\n",
    "  'symbols': [],\n",
    "  'user_mentions': [],\n",
    "  'urls': [{'url': 'https://t.co/qBcyzZ6IHn',\n",
    "    'expanded_url': 'https://twitter.com/i/web/status/1142494436930260992',\n",
    "    'display_url': 'twitter.com/i/web/status/1â€¦',\n",
    "    'indices': [117, 140]}]},\n",
    " 'metadata': {'result_type': 'popular', 'iso_language_code': 'en'},\n",
    " 'source': '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>',\n",
    " 'in_reply_to_status_id': None,\n",
    " 'in_reply_to_status_id_str': None,\n",
    " 'in_reply_to_user_id': None,\n",
    " 'in_reply_to_user_id_str': None,\n",
    " 'in_reply_to_screen_name': None,\n",
    " 'user': {'id': 33537967,\n",
    "  'id_str': '33537967',\n",
    "  'name': 'Amy Klobuchar',\n",
    "  'screen_name': 'amyklobuchar',\n",
    "  'location': '',\n",
    "  'description': 'U.S. Senator from Minnesota and candidate for President. Text AMY to 91990 to join our homegrown campaign.',\n",
    "  'url': 'http://t.co/mGGFBfggto',\n",
    "  'entities': {'url': {'urls': [{'url': 'http://t.co/mGGFBfggto',\n",
    "      'expanded_url': 'http://www.amyklobuchar.com',\n",
    "      'display_url': 'amyklobuchar.com',\n",
    "      'indices': [0, 22]}]},\n",
    "   'description': {'urls': []}},\n",
    "  'protected': False,\n",
    "  'followers_count': 705873,\n",
    "  'friends_count': 140906,\n",
    "  'listed_count': 5754,\n",
    "  'created_at': 'Mon Apr 20 14:59:36 +0000 2009',\n",
    "  'favourites_count': 30,\n",
    "  'utc_offset': None,\n",
    "  'time_zone': None,\n",
    "  'geo_enabled': False,\n",
    "  'verified': True,\n",
    "  'statuses_count': 9153,\n",
    "  'lang': 'en',\n",
    "  'contributors_enabled': False,\n",
    "  'is_translator': False,\n",
    "  'is_translation_enabled': False,\n",
    "  'profile_background_color': '026113',\n",
    "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
    "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
    "  'profile_background_tile': False,\n",
    "  'profile_image_url': 'http://pbs.twimg.com/profile_images/1059812997982511105/lgFAlE5t_normal.jpg',\n",
    "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1059812997982511105/lgFAlE5t_normal.jpg',\n",
    "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/33537967/1549830865',\n",
    "  'profile_link_color': '026113',\n",
    "  'profile_sidebar_border_color': 'F6D73F',\n",
    "  'profile_sidebar_fill_color': '89BCEE',\n",
    "  'profile_text_color': '3D3C3D',\n",
    "  'profile_use_background_image': True,\n",
    "  'has_extended_profile': False,\n",
    "  'default_profile': False,\n",
    "  'default_profile_image': False,\n",
    "  'following': False,\n",
    "  'follow_request_sent': False,\n",
    "  'notifications': False,\n",
    "  'translator_type': 'regular'},\n",
    " 'geo': None,\n",
    " 'coordinates': None,\n",
    " 'place': None,\n",
    " 'contributors': None,\n",
    " 'is_quote_status': False,\n",
    " 'retweet_count': 400,\n",
    " 'favorite_count': 769,\n",
    " 'favorited': False,\n",
    " 'retweeted': False,\n",
    " 'possibly_sensitive': False,\n",
    " 'lang': 'en'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statuses = [status, status2, status3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(statuses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/my_statuses.json\", \"w\") as fw:\n",
    "    json.dump(statuses, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/my_statuses.json\", \"r\") as fr:\n",
    "    statuses_new = json.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statuses_new[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises for JSON file writing and reading (3 questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue to use the dataframe <i>df</i> from the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = load_dataset(\"titanic\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Create a list <i>passengers</i>, in which each element is a dictionary with the keys being <i>sex</i>, <i>pclass</i>, and <i>embark_town</i> and the values being their corresponding values in <i>df</i>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Serialize <i>passengers</i> as a JSON formatted stream to a file named <i>ex_passengers.json</i> under the directory <i>data</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Deserialize the <i>ex_passengers.json</i> file under the directory <i>data</i> to a Python list named <i>passengers_new</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Pickle Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(\"titanic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to __serialize and deserialize__ Python objects include pickle.dump() and pickle.load()\n",
    "- wb indicates opening the file to write in binary mode\n",
    "- rb indicates opening the file to read in binary mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "l=(10,20,30,df)\n",
    "with open(\"data/list.pkl\", \"wb\") as fwb:\n",
    "    pickle.dump(l, fwb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/list.pkl\", \"rb\") as frb:\n",
    "    a,b,c,mydf = pickle.load(frb)\n",
    "\n",
    "mydf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"data/df.pkl\", \"wb\") as fwb:\n",
    "    pickle.dump(df, fwb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(\"data/df.pkl\", \"rb\") as frb:\n",
    "    df_new = pickle.load(frb)\n",
    "    \n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use __joblib.dump() and joblib.load()__ to save Python objects to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "with open(\"data/df_jl.pkl\", \"wb\") as fwb:\n",
    "    joblib.dump(df, fwb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "with open(\"data/df_jl.pkl\", \"rb\") as frb:\n",
    "    df_new2 = joblib.load(frb)\n",
    "\n",
    "df_new2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import requests\n",
    "import io\n",
    "\n",
    "dow = web.DataReader('^DJI', 'stooq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dow.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stooq.com/q/d/l/?s=^dji&i=d\n",
    "\n",
    "url = 'https://stooq.com/q/d/l/'\n",
    "params ={'s':'^dji',\n",
    "         'i':'d'\n",
    "        }\n",
    "\n",
    "r = requests.post(url,data=params)\n",
    "if r.ok:\n",
    "    data = r.content.decode('utf8')\n",
    "    df = pd.read_csv(io.StringIO(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with SQLite3 Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__SQLite3__ is relational database delivered with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a connection to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sqlite3 as sq3\n",
    "\n",
    "filepath=os.path.join(os.getcwd(), 'data', 'numbs_db.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sq3.connect(filepath)\n",
    "\n",
    "q=con.execute       # defines alias for the con.execute method\n",
    "\n",
    "# defines alias for the con.executemany method, which allows us to write all the data at once as np array\n",
    "qm=con.executemany "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new table in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q('Drop Table If Exists nums')\n",
    "\n",
    "q('Create Table nums (No1 Real, No2 Real, No3 Real, No4 Real, No5 Real)')\n",
    "\n",
    "con.commit() # commit the changes just made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create some data to insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "data = np.random.standard_normal((100000,5)).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert rows from data all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qm('Insert Into nums Values(?,?,?,?,?)', data)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert rows from data one at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in data:\n",
    "    q('Insert into nums values(?,?,?,?,?)', (row[0], row[1], row[2], row[3], row[4]))\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch rows from database one at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pointer = q('select * from nums')\n",
    "\n",
    "for row in pointer:\n",
    "    print(pointer.fetchone())  # do whatever I need to do with these rows one at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fecth all rows at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=q('Select * From nums').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(rows))\n",
    "\n",
    "print(type(rows[0]))\n",
    "\n",
    "rows[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manage the connection with the context manager ('with')\n",
    "\n",
    "- No need to close the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sq3.connect(filepath) as con:\n",
    "    q=con.execute\n",
    "    qm=con.executemany\n",
    "    q('Drop Table If Exists nums')\n",
    "    q('Create Table nums (No1 Real, No2 Real, No3 Real, No4 Real, No5 Real)')\n",
    "    con.commit()\n",
    "    qm('Insert Into nums Values(?,?,?,?,?)', data)\n",
    "    con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sq3.connect(filepath) as con:\n",
    "    rows=q('Select * From nums').fetchall()\n",
    "    \n",
    "rows[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work directly with Pandas Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3 as sq3\n",
    "\n",
    "filepath=os.path.join(os.getcwd(), 'data', 'numbs_db.db')\n",
    "con2 = sq3.connect(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a df from the numpy data\n",
    "- Rename the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.columns=['Num1','Num2','Num3','Num4','Num5']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a Date column to the dataframe\n",
    "\n",
    "- Using list comprehension\n",
    "- Reorder the columns so Date is first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "df['Date'] = [datetime.datetime.now() for i in range(len(df))]\n",
    "\n",
    "df=df[['Date','Num1','Num2','Num3','Num4','Num5']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use pandas to_sql method to convert the dataframe to a database\n",
    "\n",
    "- Pass the name of the table and connection to use\n",
    "- if_exists='replace' indicates to delete the table if it already exists. Other options include fail and append\n",
    "- index=false indicates whether to write the dataframe row index as a column\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_sql.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql('numbers', con=con2, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read from database into a pandas dataframe\n",
    "\n",
    "- Provide the query string and connection to use, at a minimum\n",
    "- Other parameters available\n",
    "- Reading the whole table or query results as a pandas dataframe brings data into memory, generally increasing analytics speed\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_sql('Select * From numbers', con2)\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Context Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sq3.connect(filepath) as con2:\n",
    "    df.to_sql('numbers', con=con2, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sq3.connect(filepath) as con2:\n",
    "    df3=pd.read_sql('Select * From numbers', con2)\n",
    "\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with an ODBC Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "import getpass\n",
    "\n",
    "# Parameters\n",
    "\n",
    "cnx = pyodbc.connect(\n",
    "        'Driver={IBM DB2 ODBC Driver}; '\n",
    "        'Hostname=XXX.XX.SOMEDOMAIN.COM; '\n",
    "        'Port=7805; '\n",
    "        'Protocol=TCPIP; '\n",
    "        'Database=DatabaseName; '\n",
    "        'CurrentSchema=DB2; '\n",
    "        'UID=%s; '\n",
    "        'PWD = %s' % (input(\"enter username:\"),getpass.getpass(\"enter password: \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlstring = \"SELECT K_DT AS DATE ,COUNT(DISTINCT K_ID) AS IDS FROM DB2.FACT_TABLE GROUP BY K_DT ORDER BY DATE\"\n",
    "          \n",
    "df= pd.read_sql(sqlstring, cnx)\n",
    "\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
