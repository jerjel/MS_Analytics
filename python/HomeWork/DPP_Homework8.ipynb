{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Programming in Python | BAIS:6040\n",
    "\n",
    "# Homework 8. Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the homework, fill in the commands needed to finish all of the exercises below. Program everything inside this notebook. If the exercises request that you store information within certain variables, please use those specific variables names (case sensitive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have a dataframe <i>dfdi</i> with the features of diamonds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "0   0.23    Ideal     E     SI2   61.5   55.0  326.0  3.95  3.98  2.43\n",
       "1   0.21  Premium     E     SI1   59.8   61.0  326.0  3.89  3.84  2.31\n",
       "2   0.23     Good     E     VS1   56.9   65.0  327.0  4.05  4.07  2.31\n",
       "3   0.29  Premium     I     VS2   62.4   58.0  334.0  4.20  4.23  2.63\n",
       "4   0.31     Good     J     SI2   63.3   58.0  335.0  4.34  4.35  2.75"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from seaborn import load_dataset\n",
    "dfdi = load_dataset(\"diamonds\")\n",
    "np.random.seed(0)\n",
    "for _ in range(20): \n",
    "        r = np.random.randint(len(dfdi)) \n",
    "        c = np.random.randint(low=1, high=len(dfdi.columns)) \n",
    "        dfdi.iloc[r, c] = np.nan\n",
    "dfdi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the questions below, let's aim to build a <b>logistic regression</b> model using the diamond dataset that is able to predict whether the price of a new diamond will be greater than the median price in the existing dataset based on its carat, cut, color, clarity, depth, table, x, y, and z. This is a __classification__ model using __logistic regression__ not a __regression__ problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Build a list called categorical_cols to indicate you intend to use <i>cut</i>, <i>color</i>, and <i>clarity</i> as categorical variables. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "categorical_cols = [\"cut\", \"color\", \"clarity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Build a list called continuous_cols to indicate you intend to use the remaining 6 features as numeric variables. Then concatenate the two lists into a list called predictor_cols. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "continuous_cols = [\"carat\", \"depth\", \"table\", \"x\", \"y\", \"z\"]\n",
    "predictor_cols = categorical_cols + continuous_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Create, and add to the dataframe, the new boolean target variable called price_median_greater. Assign the price_median_greater target variable name to a variable called target_col. (15 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "dfdi[\"price_median_greater\"] = dfdi[\"price\"] > dfdi.price.median()\n",
    "target_col = \"price_median_greater\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Split <i>X</i> and <i>y</i> into two training datasets <i>X_train</i> and <i>y_train</i> and two test datasets <i>X_text</i> and <i>y_test</i>. Set the `test_size` to 0.25 and `random_state` to 0. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "X=dfdi[predictor_cols]\n",
    "y=dfdi[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Build a pipeline for the necessary preprocessing and the model. Use the median to replace missing values of numeric variables and the most frequent value to replace missing values for categorical variables.  The numeric variables should be scaled with StandardScaler and the categorical variables should be One Hot Encoded (without dropping any columns). The handle_unknown parameter of OneHotEncoder should be set to 'ignore'. You can use the default parameter values for Logistic Regression. (25 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('preprocess',\n",
       "  ColumnTransformer(remainder='passthrough',\n",
       "                    transformers=[('num',\n",
       "                                   Pipeline(steps=[('impute',\n",
       "                                                    SimpleImputer(strategy='median')),\n",
       "                                                   ('scale', StandardScaler())]),\n",
       "                                   ['carat', 'depth', 'table', 'x', 'y', 'z']),\n",
       "                                  ('cat',\n",
       "                                   Pipeline(steps=[('impute',\n",
       "                                                    SimpleImputer(strategy='most_frequent')),\n",
       "                                                   ('enc',\n",
       "                                                    OneHotEncoder(dtype=<class 'numpy.int32'>,\n",
       "                                                                  handle_unknown='ignore',\n",
       "                                                                  sparse=False))]),\n",
       "                                   ['cut', 'color', 'clarity'])])),\n",
       " ('rgr', LogisticRegression())]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer here\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "\n",
    "num_transformer = Pipeline(steps=[('impute', SimpleImputer(strategy='median'))\n",
    "                                 ,('scale', StandardScaler())])\n",
    "\n",
    "cat_transformer = Pipeline(steps=[('impute',SimpleImputer(strategy='most_frequent'))\n",
    "                                 ,('enc', OneHotEncoder(sparse = False, handle_unknown='ignore'\n",
    "                                                        ,dtype=np.int32))])\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', num_transformer, continuous_cols),\n",
    "                                               ('cat', cat_transformer, categorical_cols)]\n",
    "                                 ,remainder='passthrough')\n",
    "\n",
    "pipe_logistic = Pipeline(steps=[('preprocess', preprocessor)\n",
    "                            ,('rgr', LogisticRegression())])\n",
    "\n",
    "pipe_logistic.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Fit the pipeline to the training dataset. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocess',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('num',\n",
       "                                                  Pipeline(steps=[('impute',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scale',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['carat', 'depth', 'table',\n",
       "                                                   'x', 'y', 'z']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('impute',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('enc',\n",
       "                                                                   OneHotEncoder(dtype=<class 'numpy.int32'>,\n",
       "                                                                                 handle_unknown='ignore',\n",
       "                                                                                 sparse=False))]),\n",
       "                                                  ['cut', 'color',\n",
       "                                                   'clarity'])])),\n",
       "                ('rgr', LogisticRegression())])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer here\n",
    "pipe_logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Get the accuracy score against the training and test datasets and store in the variables train_acc and test_acc respectively. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "train_acc = pipe_logistic.score(X_train, y_train)\n",
    "test_acc = pipe_logistic.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy  0.9792361883574342\n",
      "Test accuracy  0.9789395624768261\n"
     ]
    }
   ],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "\n",
    "print(\"Training accuracy \", train_acc)\n",
    "print(\"Test accuracy \", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Using the first observation in the test dataset, store the answer to whether the price would be predicted to be above the median in a variable called predict_label. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "predict_label = pipe_logistic.predict(X_test.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "\n",
    "predict_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. Using the last observation in the test dataset, store the predicted probability the price would be above the median in a variable called predict_prob. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "predict_prob = pipe_logistic.predict(X_test.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "\n",
    "predict_prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
