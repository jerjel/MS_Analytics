{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics | BAIS:6100\n",
    "# Module 4: Keyword Analysis and Visualization - Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructor: Kang-Pyo Lee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises - Keyword Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter hashtag options:\n",
    "- ai\n",
    "- bitcoin\n",
    "- blacklivesmatter\n",
    "- bts\n",
    "- covid19\n",
    "- fakenews\n",
    "- innovation\n",
    "- mentalhealth\n",
    "- metoo\n",
    "- startup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a Twitter hashtag you're interested in and save it in the `hashtag` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag = \"mentalhealth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "\n",
    "months = [\"202012\", \"202011\", \"202010\", \"202009\", \"202008\", \"202007\", \n",
    "          \"202006\", \"202005\", \"202004\", \"202003\", \"202002\", \"202001\"]\n",
    "\n",
    "N = 1000\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for month in months:\n",
    "    dftmp = pd.read_csv(\"classdata/tweets/tweets_{}_{}.csv\".format(hashtag, month), sep=\"\\t\", quoting=3)\n",
    "    \n",
    "    ##############################################\n",
    "    # Create a random sample of n rows.\n",
    "    ##############################################\n",
    "    if len(dftmp) > N:\n",
    "        dftmp = dftmp.sample(n=N)\n",
    "    ##############################################\n",
    "    \n",
    "    df = pd.concat([df, dftmp])\n",
    "    print(\"{}: {:,}\".format(month, len(dftmp)))\n",
    "\n",
    "print(\"Total number of tweets in df: {:,}\\n\".format(len(df)))\n",
    "\n",
    "df.user_name = df.user_name.astype(str)\n",
    "df.text = df.text.astype(str)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Import the following modules:\n",
    "- Counter from collections\n",
    "- gender_guesser.detector as gender\n",
    "- Image from IPython.display\n",
    "- nltk\n",
    "- string\n",
    "- TextBlob from textblob\n",
    "- WordCloud from wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Add two new columns `tagged_words` and `polarity` to `df`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "df[[\"text\", \"tagged_words\", \"polarity\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. List the top-50 most common words in the `text` column along with their frequencies, considering only the global English stopwords. You may reuse the `get_counter` function you have used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "def get_counter(dataframe, stopwords=[], target_tag=None):\n",
    "    counter = Counter()\n",
    "    \n",
    "    for l in dataframe.tagged_words:\n",
    "        word_set = set()\n",
    "\n",
    "        for t in l:\n",
    "            word = t[0].lower()\n",
    "            tag = t[1]\n",
    "\n",
    "            ##########################################################\n",
    "            # Check if the word is a stopword.\n",
    "            ##########################################################\n",
    "            if word in stopwords:\n",
    "                continue\n",
    "\n",
    "            if target_tag is None:\n",
    "                word_set.add(word)\n",
    "            else:\n",
    "                ##########################################################\n",
    "                # Check the tag\n",
    "                ##########################################################\n",
    "                if tag.startswith(target_tag):\n",
    "                    word_set.add(word)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        counter.update(word_set)\n",
    "        \n",
    "    return counter\n",
    "\n",
    "global_stopwords = nltk.corpus.stopwords.words(\"english\") \n",
    "counter1 = get_counter(df, global_stopwords)\n",
    "counter1.most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Examine the 50 most common words from question 3 and define your own local stopwords in a list named `local_stopwords`. Then, list the top-50 most common words and their frequencies, this time considering both the global and local stopwords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Draw a word cloud that visualizes the top-100 most common words. You may reuse the `draw_wordcloud` function you have used before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Select from `df` the rows with the polarity score larger than or equal to 0.7, i.e., strongly positive tweets. List the top-50 most common words in the selected text along with their frequencies, reusing the global and local stopwords defined earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Draw a word cloud that visualizes the top-100 most common words in the positive tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. Select from `df` the rows with the polarity score larger than or equal to 0.7, i.e., strongly positive tweets. List the top-50 most common <b>adjectives</b> in the selected text along with their frequencies, reusing the global and local stopwords defined earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. Draw a word cloud that visualizes the top-100 most common adjectives in the positive tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
