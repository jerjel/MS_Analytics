{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics | BAIS:6100\n",
    "# Module 5. Using Twitter APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructor: Kang-Pyo Lee \n",
    "\n",
    "Topics to be covered:\n",
    "- Searching for tweets using a search query\n",
    "- Retrieving tweets from a user's timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *** Please run the cells for API requests only when needed. You should be aware of the API rate limits of Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://developer.twitter.com/en/docs/basics/rate-limits <br>\n",
    "https://developer.twitter.com/en/docs/basics/rate-limiting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --user --upgrade twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the Twitter APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the four variables with your own Twitter API credentials.\n",
    "\n",
    "CONSUMER_KEY = \"\"\n",
    "CONSUMER_SECRET = \"\"\n",
    "ACCESS_TOKEN = \"\"\n",
    "ACCESS_TOKEN_SECRET = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish a connection to the Twitter APIs.\n",
    "\n",
    "auth = twitter.oauth.OAuth(ACCESS_TOKEN, ACCESS_TOKEN_SECRET, CONSUMER_KEY, CONSUMER_SECRET)\n",
    "twitter_api = twitter.Twitter(auth=auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for Tweets Using a Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the first search call to the Twitter API.\n",
    "\n",
    "q = \"iowa\"\n",
    "search_results = twitter_api.search.tweets(q=q, count=100, lang=\"en\", result_type=\"mixed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://developer.twitter.com/en/docs/tweets/search/api-reference/get-search-tweets.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `q`: a search query of 500 characters maximum, including operators\n",
    "- `count`: the number of tweets to return per page, up to a maximum of 100 \n",
    "- `lang`: restricts tweets to the given language \n",
    "- `result_type`: specifies what type of search results you would prefer to receive (mixed | recent | popular)\n",
    "\n",
    "Note that the search API has a 7-day limit. In other words, you can only search for tweets published in the past 7 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results[\"search_metadata\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(search_results[\"statuses\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A status refers to an individual tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search_results[\"statuses\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results[\"statuses\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results[\"statuses\"][0][\"user\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for status in search_results[\"statuses\"][:30]:\n",
    "    print(status[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for More Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 30                     # Number of additional calls to the search API.\n",
    "\n",
    "#########################################################################\n",
    "# 'Results' will be used for accumulating all incoming data from Twitter.\n",
    "# Start by storing the previous data in 'results'.\n",
    "#########################################################################\n",
    "\n",
    "results = []\n",
    "results += search_results[\"statuses\"]\n",
    "\n",
    "#########################################################################\n",
    "# Make N more iterative search calls with the same query.\n",
    "#########################################################################\n",
    "\n",
    "for _ in range(N):\n",
    "    try:\n",
    "        next_results = search_results[\"search_metadata\"][\"next_results\"]\n",
    "    except KeyError:\n",
    "        break\n",
    "    \n",
    "    kwargs = dict([kv.split('=') for kv in next_results[1:].split(\"&\")])\n",
    "    search_results = twitter_api.search.tweets(**kwargs)\n",
    "    \n",
    "    print(\"%d tweets retrieved.\" %len(search_results[\"statuses\"]))\n",
    "    \n",
    "    ##########################################################\n",
    "    # Add the current search results to the overall results.\n",
    "    ##########################################################\n",
    "    \n",
    "    results += search_results[\"statuses\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to Twitter's API rate policy, you can only make 180 search queries per 15-minute window. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data in a CSV File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's alwasy a good idea to save the collected data, which is temporarily in the memory, as a file for easier access to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_text(text):\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    text = text.replace(\"\\r\", \"\")\n",
    "    text = text.replace(\"\\t\", \"\")\n",
    "    text = text.replace(\"\\\"\", \"\")\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "# Write the data to a CSV file.\n",
    "###################################################################################\n",
    "\n",
    "with open(file=\"outcome/twitter_search_data.csv\", mode=\"w\", encoding=\"utf8\") as fw:\n",
    "    \n",
    "    ###########################################################################################\n",
    "    # Write the 14 column names on the first row.\n",
    "    # A tab (\\t) acts as a seperator between columns and a new line (\\n) between rows. \n",
    "    ###########################################################################################\n",
    "    \n",
    "    fw.write(\"id\\t\" +\n",
    "             \"created_at\\t\" +\n",
    "             \"text\\t\" +\n",
    "             \"is_retweet\\t\" +\n",
    "             \"retweet_created_at\\t\" +\n",
    "             \"retweet_count\\t\" +\n",
    "             \"user_id\\t\" +\n",
    "             \"user_name\\t\" +\n",
    "             \"user_screen_name\\t\" + \n",
    "             \"user_created_at\\t\" +\n",
    "             \"user_followers_count\\t\" +\n",
    "             \"user_statuses_count\\t\" +\n",
    "             \"user_location\\t\" +\n",
    "             \"user_desc\\n\")\n",
    "\n",
    "    ###########################################################################################\n",
    "    # Write the actual data starting from the second row by iterating over the 'results'.\n",
    "    # A tab (\\t) acts as a seperator between columns and a new line (\\n) as the end of a line. \n",
    "    # Mare sure the order of column names matches the order in which the column values are written.\n",
    "    ###########################################################################################\n",
    "    \n",
    "    for status in results:\n",
    "        fw.write(status[\"id_str\"] + \"\\t\")\n",
    "        fw.write(status[\"created_at\"] + \"\\t\")\n",
    "        fw.write(cleanse_text(status[\"text\"]) + \"\\t\")\n",
    "        \n",
    "        if \"retweeted_status\" in status:\n",
    "            fw.write(\"1\\t\")\n",
    "            fw.write(status[\"retweeted_status\"][\"created_at\"] + \"\\t\")\n",
    "        else:\n",
    "            fw.write(\"0\\t\")\n",
    "            fw.write(\"\\t\")\n",
    "        \n",
    "        fw.write(str(status[\"retweet_count\"]) + \"\\t\")\n",
    "        fw.write(status[\"user\"][\"id_str\"] + \"\\t\")\n",
    "        fw.write(status[\"user\"][\"name\"] + \"\\t\")\n",
    "        fw.write(status[\"user\"][\"screen_name\"] + \"\\t\")\n",
    "        fw.write(status[\"user\"][\"created_at\"] + \"\\t\")\n",
    "        fw.write(str(status[\"user\"][\"followers_count\"]) + \"\\t\")\n",
    "        fw.write(str(status[\"user\"][\"statuses_count\"]) + \"\\t\")\n",
    "        fw.write(cleanse_text(status[\"user\"][\"location\"]) + \"\\t\")\n",
    "        fw.write(cleanse_text(status[\"user\"][\"description\"]) + \"\\t\")\n",
    "        fw.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving Tweets from a User's Timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://twitter.com/cnnbrk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve recent tweets from the timeline of the CNN Breaking News on Twitter.  \n",
    "\n",
    "kwargs = {\"screen_name\": \"cnnbrk\", \"count\": 200, \"include_rts\": \"true\", \"since_id\": 1}\n",
    "statuses = twitter_api.statuses.user_timeline(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://developer.twitter.com/en/docs/tweets/timelines/api-reference/get-statuses-user_timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `screen_name`: the screen name of the user for whom to return results\n",
    "- `count`: the number of Tweets to try and retrieve, up to a maximum of 200 per distinct request\n",
    "- `include_rts`: when set to false, the timeline will strip any native retweets (though they will still count toward both the maximal length of the timeline and the slice selected by the count parameter)\n",
    "- `since_id`: returns results with an ID greater than (that is, more recent than) the specified ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(statuses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "statuses[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving More Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################\n",
    "# 'Results' will be used for accumulating all incoming data from Twitter.\n",
    "# Start by storing the previous data in 'results'.\n",
    "#########################################################################\n",
    "\n",
    "results = []\n",
    "results += statuses\n",
    "\n",
    "#########################################################################\n",
    "# Make more iterative user timeline calls\n",
    "#########################################################################\n",
    "\n",
    "N = 15          # Maximum number of calls to be made.\n",
    "\n",
    "i = 1\n",
    "while (i <= N) and (len(statuses) > 0):\n",
    "    \n",
    "    ##########################################\n",
    "    # Add a new key 'max_id' to kwargs \n",
    "    ##########################################\n",
    "    \n",
    "    kwargs[\"max_id\"] = min([status[\"id\"] for status in statuses]) - 1\n",
    "    statuses = twitter_api.statuses.user_timeline(**kwargs)\n",
    "    \n",
    "    print(\"%d tweets retrieved.\" %len(statuses))\n",
    "    \n",
    "    ##########################################################\n",
    "    # Add the current results to the overall results.\n",
    "    ##########################################################\n",
    "    \n",
    "    results += statuses\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_id: returns results with an ID less than (that is, older than) or equal to the specified ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to Twitter's API rate policy, you can only make 900 statuses queries per 15-minute window. In addition, this can only return up to 3,200 of a userâ€™s most recent Tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data in a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file=\"outcome/twitter_user_timeline_data.csv\", mode=\"w\", encoding=\"utf8\") as fw:\n",
    "    fw.write(\"id\\t\" +\n",
    "             \"created_at\\t\" +\n",
    "             \"text\\t\" +\n",
    "             \"is_retweet\\t\" +\n",
    "             \"retweet_created_at\\t\" +\n",
    "             \"retweet_count\\t\" +\n",
    "             \"user_id\\n\")\n",
    "\n",
    "    for status in results:\n",
    "        fw.write(status[\"id_str\"] + \"\\t\")\n",
    "        fw.write(status[\"created_at\"] + \"\\t\")\n",
    "        fw.write(cleanse_text(status[\"text\"]) + \"\\t\")\n",
    "        \n",
    "        if \"retweeted_status\" in status:\n",
    "            fw.write(\"1\\t\")\n",
    "            fw.write(status[\"retweeted_status\"][\"created_at\"] + \"\\t\")\n",
    "        else:\n",
    "            fw.write(\"0\\t\")\n",
    "            fw.write(\"\\t\")\n",
    "        \n",
    "        fw.write(str(status[\"retweet_count\"]) + \"\\t\")\n",
    "        fw.write(status[\"user\"][\"id_str\"])\n",
    "        fw.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
