{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analytics | BAIS:6100\n",
    "# Module 10: Text Similarity (Exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructor: Kang-Pyo Lee "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter hashtag options:\n",
    "- ai\n",
    "- bitcoin\n",
    "- blacklivesmatter\n",
    "- bts\n",
    "- covid19\n",
    "- fakenews\n",
    "- innovation\n",
    "- mentalhealth\n",
    "- metoo\n",
    "- startup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a Twitter hashtag you're interested in and save it in the `hashtag` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "hashtag = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 150)\n",
    "\n",
    "months = [\"202012\", \"202011\", \"202010\", \"202009\", \"202008\", \"202007\", \n",
    "          \"202006\", \"202005\", \"202004\", \"202003\", \"202002\", \"202001\"]\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for month in months:\n",
    "    dftmp = pd.read_csv(\"classdata/tweets/tweets_{}_{}.csv\".format(hashtag, month), sep=\"\\t\", quoting=3)\n",
    "    \n",
    "    ##############################################\n",
    "    # Create a random sample of N rows.\n",
    "    ##############################################\n",
    "    if len(dftmp) > N:\n",
    "        dftmp = dftmp.sample(n=N)\n",
    "    ##############################################\n",
    "    \n",
    "    df = pd.concat([df, dftmp])\n",
    "    print(\"{}: {:,}\".format(month, len(dftmp)))\n",
    "\n",
    "print(\"Total number of tweets in df: {:,}\\n\".format(len(df)))\n",
    "\n",
    "df.user_name = df.user_name.astype(str)\n",
    "df.text = df.text.astype(str)\n",
    "\n",
    "df = df.drop_duplicates([\"text\"])\n",
    "df.index = range(len(df))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop all duplicates in the `text` column and then re-index the rows of the dataframe such that it ranges from 0 to the length - 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Get all the unique words from the first 200 values in the `text` column of `df`, sort them in alphabetical order, and save them in a list named `unique_words`. Use the `get_unique_words` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "def get_unique_words(text_list):\n",
    "    all_words = set()\n",
    "    \n",
    "    for text in text_list:\n",
    "        words = nltk.word_tokenize(text)\n",
    "        for word in words:\n",
    "            if re.search(\"^[a-zA-Z][a-zA-Z0-9]+\", word):  # Any word starting with an alphabet letter followed by any alphanumerical characters\n",
    "                all_words.add(word.lower())\n",
    "                \n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Write a fuction named `find_similar_words` that take two parameters `word_list` and `distance` and print all the pairs of words in `word_list` that have the Levenshtein distance of `distance`. Set the default value for the `distance` parameter to 1. Filter out the words that have fewer than 5 characters or end with '…'. After writing the function, test the function by passing `unique_words` you got from question 1 for the first argument and 1 and 2, respectively, for the second argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_levenshtein_dist(seq1, seq2):\n",
    "    size_x = len(seq1) + 1\n",
    "    size_y = len(seq2) + 1\n",
    "    matrix = np.zeros ((size_x, size_y), dtype=int)\n",
    "    for x in range(size_x):\n",
    "        matrix [x, 0] = x\n",
    "    for y in range(size_y):\n",
    "        matrix [0, y] = y\n",
    "\n",
    "    for x in range(1, size_x):\n",
    "        for y in range(1, size_y):\n",
    "            if seq1[x-1] == seq2[y-1]:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1, y] + 1,\n",
    "                    matrix[x-1, y-1],\n",
    "                    matrix[x, y-1] + 1\n",
    "                )\n",
    "            else:\n",
    "                matrix [x,y] = min(\n",
    "                    matrix[x-1,y] + 1,\n",
    "                    matrix[x-1,y-1] + 1,\n",
    "                    matrix[x,y-1] + 1\n",
    "                )\n",
    "    \n",
    "    return (matrix[size_x - 1, size_y - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "find_similar_words(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "find_similar_words(unique_words, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Create a TF-IDF vectorizer by applying the l2 normalization for the `norm` parameter, using the global and local stopwords below for the `stop_words` parameter, and setting the `max_df` to 0.7. Then, using the vectorizer, transform the `text` column of `df` to a document-term matrix named `dtm`. Lastly, create a dataframe named `df_sim` that contains all the pairwise cosine similarities of `dtm` as its data and the index of `df` as both the index and columns of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "global_stopwords = stopwords.words(\"english\")\n",
    "local_stopwords = [c for c in string.punctuation] +\\\n",
    "                  ['’', '``', '…', '...', \"''\", '‘', '“', '”', \"'m\", \"'re\", \"'s\", \"'ve\", 'amp', 'https', \"n't\", 'rt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "df_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Using `df_sim`, print all the pairs of tweet texts in the `text` column of `df` that have the cosine similarity strictly higher than 0.7 and strictly lower than 1. Skip if the first 20 characters of one text are in the other text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have a new dataframe `df2` with two columns `text1` and `text2`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df.text.sample(n=10)\n",
    "data = []\n",
    "\n",
    "for text1 in texts:\n",
    "    for text2 in texts:\n",
    "        if text1 != text2:\n",
    "            data.append([text1, text2])\n",
    "            \n",
    "df2 = pd.DataFrame(data=data, columns=[\"text1\", \"text2\"])\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Add a new column `sim_jaccard`, such that the new column has the Jaccard similarity of the two texts from the `text1` and `text2` columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [word.lower() for word in words if word not in string.punctuation]\n",
    "    \n",
    "    return words\n",
    "\n",
    "def get_jaccard_sim(text1, text2): \n",
    "    a = set(tokenize(text1)) \n",
    "    b = set(tokenize(text2))\n",
    "    i = a & b\n",
    "    u = a | b\n",
    "    \n",
    "    return len(i) / len(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "df2[[\"text1\", \"text2\", \"sim_jaccard\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Add a new column `sim_cosine`, such that the new column has the cosine similarity of the two texts from the `text1` and `text2` columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_sim(text1, text2):\n",
    "    corpus = [text1, text2]\n",
    "    vectorizer = TfidfVectorizer(use_idf=False, norm=None)\n",
    "    dtm = vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    return cosine_similarity(dtm)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your answer here. (Do not make any change to this cell. Just run this cell.)\n",
    "df2[[\"text1\", \"text2\", \"sim_jaccard\", \"sim_cosine\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
